

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>BUSINESS UNDERSTANDING &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'PSD_Mubessirul Ummah_210411100140_Water Quality';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">BUSINESS UNDERSTANDING</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FPSD_Mubessirul Ummah_210411100140_Water Quality.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/PSD_Mubessirul Ummah_210411100140_Water Quality.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>BUSINESS UNDERSTANDING</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">BUSINESS UNDERSTANDING</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determine-business-objectives-menentukan-tujuan-bisnis">Determine Business Objectives (Menentukan Tujuan Bisnis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#access-situation-menilai-situasi">Access Situation (Menilai Situasi)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determine-data-mining-goals-menentukan-tujuan-data-mining">Determine Data Mining Goals (Menentukan Tujuan Data Mining)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#produce-project-plan-menghasilkan-rencana-proyek">Produce Project Plan (Menghasilkan Rencana Proyek)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding">DATA UNDERSTANDING</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-dataset">Deskripsi Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-fitur-dataset">Deskripsi Fitur Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-tipe-data-fitur">Deskripsi Tipe Data Fitur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-missing-value">Identifikasi Missing Value</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-data-duplicated">Identifikasi Data Duplicated</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-sebaran-kelas-data">Identifikasi Sebaran Kelas Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-outlier">Identifikasi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-data">Eksplorasi Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram-sebaran-frekuensi-data-setiap-kolom">Histogram Sebaran Frekuensi Data Setiap Kolom</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-korelasi">Matrix Korelasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diagram-lingkaran-perbandingan-jumlah-data-kelas">Diagram Lingkaran perbandingan jumlah data kelas</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-procesing">Pre-Procesing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-missing-data">Handling Missing Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-cleaning">Data Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-imbalanced-data">Handling Imbalanced Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-kelas-data-awal">Perbandingan kelas data awal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-balancing-data">Proses Balancing Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">Feature Scaling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-data">Splitting Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pycaret-seleksi-model">Pycaret Seleksi Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#light-gradient-boosting-machine">Light Gradient Boosting Machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-classifier">Gradient Boosting Classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-clasifier">Decision Tree Clasifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ada-boost-classifier">Ada Boost Classifier</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection">Feature Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-light-gradient-boosting-machine">Pencarian Fitur Terbaik Light Gradient Boosting Machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-gradient-boosting-classifier">Pencarian Fitur Terbaik Gradient Boosting Classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-random-forest">Pencarian Fitur Terbaik Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Decision Tree Clasifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Ada Boost Classifier</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Light Gradient Boosting Machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Gradient Boosting Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Random Forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Decision Tree Clasifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Ada Boost Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-metode">Perbandingan Metode</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi">Evaluasi</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Light Gradient Boosting Machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Gradient Boosting Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Random Forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">Decision Tree Clasifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">Ada Boost Classifier</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment">Deployment</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <center><b>Proyek Sains Data: Water Quality<b></center><table>
    <tr>
    <td>Nama</td>
    <td>:</td>
    <td>Mubessirul Ummah</td>
</tr>
<tr>
    <td>NIM</td>
    <td>:</td>
    <td>210411100140</td>
</tr>
<tr>
    <td>Kelas</td>
    <td>:</td>
    <td>Proyek Sains Data IF-5B</td>
</tr>
</table><img src="Water-Sampling-scaled.jpg" alt="Logo"><section class="tex2jax_ignore mathjax_ignore" id="business-understanding">
<h1>BUSINESS UNDERSTANDING<a class="headerlink" href="#business-understanding" title="Permalink to this heading">#</a></h1>
<p>Tahapan business understanding merupakan tahap awal dari sebuah proyek data analytics. Tahapan ini akan dapat menghasilkan perencanaan sebuah proyek data analytics yang jelas tujuannya dan pemahaman menyeluruh tentang proses bisnis, seperti membuat peta rute untuk memastikan rencana yang baik. Berikut Business Understanding dari proyek saya kali ini :</p>
<section id="determine-business-objectives-menentukan-tujuan-bisnis">
<h2>Determine Business Objectives (Menentukan Tujuan Bisnis)<a class="headerlink" href="#determine-business-objectives-menentukan-tujuan-bisnis" title="Permalink to this heading">#</a></h2>
<p>Air merupakan salah satu sumber daya alam esensial untuk kelangsungan hidup seluruh makhluk hidup di dunia ini. Kita memerlukan air untuk kebutuhan kita sehari-hari, begitu juga dengan tanaman dan hewan yang memerlukan air untuk kelangsungan hidupnya. Menurut data dari World Health Organization (WHO), diperkirakan sebanyak 1.1 Miliar orang tidak memiliki akses untuk mendapatkan air yang layak minum dan 2.6 Miliar lainnya tidak mendapatkan fasilitas sanitasi yang baik.
<i>Pengolahan data ini bertujuan untuk menilai dan mengategorikan kualitas air sebagai “aman” atau “tidak aman” menggunakan teknik klasifikasi</i>. Ini sejalan dengan tujuan lebih besar untuk memastikan air minum yang aman bagi masyarakat.
Dalam pengolahan data kali ini akan dilakukan pencarian terhadap metode klasifikasi dan Apa fitur utama yang paling signifikan berkontribusi pada klasifikasi air sebagai aman atau tidak aman?</p>
</section>
<section id="access-situation-menilai-situasi">
<h2>Access Situation (Menilai Situasi)<a class="headerlink" href="#access-situation-menilai-situasi" title="Permalink to this heading">#</a></h2>
<p>Setelah memahami dengan lebih spesifik tujuan bisnis terkait penilaian kualitas air, langkah berikutnya adalah melakukan assessment yang mencakup ketersediaan sumber daya, mitigasi risiko, dan terutama ketersediaan data kualitas air. Data mengenai kualitas air dapat bervariasi tergantung pada sumbernya, dan metode analitika data yang akan diterapkan akan sangat dipengaruhi oleh ketersediaan data tersebut.
Dalam konteks kualitas air, pertanyaan yang muncul adalah, “Apa fitur utama yang paling signifikan berkontribusi pada klasifikasi air sebagai aman atau tidak aman?” Untuk menjawab pertanyaan ini, metode klasifikasi atau estimasi dapat diterapkan. Misalnya, algoritma machine learning seperti Random Forest atau Logistic Regression dapat digunakan untuk mengidentifikasi faktor-faktor utama yang membedakan air aman dan tidak aman.</p>
</section>
<section id="determine-data-mining-goals-menentukan-tujuan-data-mining">
<h2>Determine Data Mining Goals (Menentukan Tujuan Data Mining)<a class="headerlink" href="#determine-data-mining-goals-menentukan-tujuan-data-mining" title="Permalink to this heading">#</a></h2>
<p>Tujuan Data Mining kali ini yakni untuk mengembangkan model klasifikasi yang dapat mengidentifikasi apakah suatu sampel air aman atau tidak aman berdasarkan parameter-parameter tertentu.
Air minum yang layak konsumsi harus memenuhi beberapa kriteria, seperti tidak berwarna, tidak berbau, dan tidak mengandung zat berbahaya. Kriteria ini penting untuk diketahui agar terhindar dari masalah kesehatan akibat konsumsi air minum yang tidak layak.
dalam menilai suatu air dikategorikan layak atau tidak layak di konsumsi jika berdasarkan kandungan zat yang ada di dalam air, maka berikut ini beberapa ciri atau kandungan air yang mempengaruhi kualitas air:</p>
<ol class="arabic simple">
<li><p>aluminium berbahaya jika lebih besar dari 2,8</p></li>
<li><p>ammonia berbahaya jika lebih besar dari 32,5</p></li>
<li><p>arsenic berbahaya jika lebih besar dari 0,01</p></li>
<li><p>barium berbahaya jika lebih besar dari 2</p></li>
<li><p>cadmium berbahaya jika lebih besar dari 0,005</p></li>
<li><p>chloramine berbahaya jika lebih besar dari 4</p></li>
<li><p>chromium berbahaya jika lebih besar dari 0,1</p></li>
<li><p>copper berbahaya jika lebih besar dari 1,3</p></li>
<li><p>flouride berbahaya jika lebih besar dari 1,5</p></li>
<li><p>bacteria berbahaya jika lebih besar dari 0</p></li>
<li><p>viruses berbahaya jika lebih besar dari 0</p></li>
<li><p>lead berbahaya jika lebih besar dari 0,015</p></li>
<li><p>nitrates berbahaya jika lebih besar dari 10</p></li>
<li><p>nitrites berbahaya jika lebih besar dari 1</p></li>
<li><p>mercury erbahaya jika lebih besar dari 0,002</p></li>
<li><p>perchlorate berbahaya jika lebih besar dari 56</p></li>
<li><p>radium berbahaya jika lebih besar dari 5</p></li>
<li><p>selenium berbahaya jika lebih besar dari 0,5</p></li>
<li><p>silver berbahaya jika lebih besar dari 0,1</p></li>
<li><p>uranium berbahaya jika lebih besar dari 0,3</p></li>
</ol>
<p>Kemudian berdasarkan ciri-ciri di atas, suatu air bisa dikategorikan menjadi kelas 1 (safe atau aman) dan 0 (not safe atau tidak aman).</p>
</section>
<section id="produce-project-plan-menghasilkan-rencana-proyek">
<h2>Produce Project Plan (Menghasilkan Rencana Proyek)<a class="headerlink" href="#produce-project-plan-menghasilkan-rencana-proyek" title="Permalink to this heading">#</a></h2>
<p>Langkah-langkah Proyek sebagai berikut :
<img src="skema.jpg" alt="Logo"></p>
<ul class="simple">
<li><p>Menentukan bussiness understanding</p></li>
<li><p>Mengumpulkan dataset kualitas air yang mencakup informasi parameter-parameter yang sesuai.</p></li>
<li><p>Melakukan data understanding untuk memahami sebuah data sepert jumlahnya, daftar kolom, tipe data kolom, banayknya kelas, dan mengetahui data tersebut perlu atau tidak untuk dilakukan preprocessing.</p></li>
<li><p>Melakukan preprocessing terhadap dataset sebelum diterapkan teknik klasifikasi.</p></li>
<li><p>Membagi dataset menjadi set pelatihan (training set) dan set pengujian (testing set).</p></li>
<li><p>Menentukan teknik klasifikasi yang paling sesuai untuk proyek ini.</p></li>
<li><p>Mengembangkan, melatih, dan mengevaluasi model klasifikasi menggunakan set pelatihan.</p></li>
<li><p>Mengukur performa model menggunakan set pengujian.</p></li>
<li><p>Melakukan evaluasi terhadap model yang telah dikembangkan.</p></li>
<li><p>Mengimplementasikan model dalam aplikasi streamlit untuk mengetahui kualitas air.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="c1"># from keras.models import Sequential</span>
<span class="c1"># from keras.layers import Dense</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">mutual_info_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-understanding">
<h1>DATA UNDERSTANDING<a class="headerlink" href="#data-understanding" title="Permalink to this heading">#</a></h1>
<p>Data Understanding adalah tahap yang fokus pada eksplorasi dan pemahaman awal terhadap data yang akan digunakan dalam suatu proyek analisis data. Tahap ini merupakan langkah untuk memahami karakteristik, struktur, dan konten atau isi dari data sebelum melakukan analisis lebih lanjut. data understanding dipakai untuk memeriksa data sehingga dapat mengidentifikasi masalah pada data yang kita dapatkan.</p>
<section id="deskripsi-dataset">
<h2>Deskripsi Dataset<a class="headerlink" href="#deskripsi-dataset" title="Permalink to this heading">#</a></h2>
<p>Datasest waterquality merupakan kumpulan data yang dibuat dari data imajiner kualitas air di lingkungan perkotaan. Dataset ini mencakup data kadar mikroorganisme yang terkandung di dalam air seperti kadar aluminium, ammonia, arsenic, barium, cadmium, chloramine, chromium, copper, flouride, bacteria, viruses, lead, nitrates, nitrites, mercury, perchlorate, radium, selenium, silver, dan uranium. Data tersebut berisi 21 atribut dan 7999 record, record tersebut diberi label dengan variabel kelas is_safe, yang memungkinkan klasifikasi data menggunakan nilai 1 (safe atau aman) dan 0 (not_safe atau tidak aman) dikonsumsi.
data ini saya dapatkan dari Kaggel dengan link berikut : <a class="reference external" href="https://www.kaggle.com/datasets/mssmartypants/water-quality/">https://www.kaggle.com/datasets/mssmartypants/water-quality/</a>.</p>
<p>dataset tersebut berisi “synthetic water quality data” atau “simulated water quality data” atau dengan kata lain sample dari data yang bersifat fiktif atau imajiner yang dibuat untuk keperluan pendidikan dan latihan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca data dari file csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-2-d8df9a89f9f6&gt;</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Membaca data dari file csv</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">df</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>                 <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>                     <span class="n">kwargs</span><span class="p">[</span><span class="n">new_arg_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_arg_value</span>
<span class="ne">--&gt; </span><span class="mi">211</span>             <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span> 
<span class="g g-Whitespace">    </span><span class="mi">213</span>         <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">wrapper</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">329</span>                     <span class="n">stacklevel</span><span class="o">=</span><span class="n">find_stack_level</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">330</span>                 <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">331</span>             <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">332</span> 
<span class="g g-Whitespace">    </span><span class="mi">333</span>         <span class="c1"># error: &quot;Callable[[VarArg(Any), KwArg(Any)], Any]&quot; has no</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">read_csv</span><span class="nt">(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">948</span>     <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwds_defaults</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">949</span> 
<span class="ne">--&gt; </span><span class="mi">950</span>     <span class="k">return</span> <span class="n">_read</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">951</span> 
<span class="g g-Whitespace">    </span><span class="mi">952</span> 

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">_read</span><span class="nt">(filepath_or_buffer, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">603</span> 
<span class="g g-Whitespace">    </span><span class="mi">604</span>     <span class="c1"># Create the parser.</span>
<span class="ne">--&gt; </span><span class="mi">605</span>     <span class="n">parser</span> <span class="o">=</span> <span class="n">TextFileReader</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">606</span> 
<span class="g g-Whitespace">    </span><span class="mi">607</span>     <span class="k">if</span> <span class="n">chunksize</span> <span class="ow">or</span> <span class="n">iterator</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">__init__</span><span class="nt">(self, f, engine, **kwds)</span>
<span class="g g-Whitespace">   </span><span class="mi">1440</span> 
<span class="g g-Whitespace">   </span><span class="mi">1441</span>         <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="p">:</span> <span class="n">IOHandles</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">-&gt; </span><span class="mi">1442</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_engine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_engine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1443</span> 
<span class="g g-Whitespace">   </span><span class="mi">1444</span>     <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py</span> in <span class="ni">_make_engine</span><span class="nt">(self, f, engine)</span>
<span class="g g-Whitespace">   </span><span class="mi">1733</span>                 <span class="k">if</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1734</span>                     <span class="n">mode</span> <span class="o">+=</span> <span class="s2">&quot;b&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1735</span>             <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="o">=</span> <span class="n">get_handle</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1736</span>                 <span class="n">f</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1737</span>                 <span class="n">mode</span><span class="p">,</span>

<span class="nn">/usr/local/lib/python3.10/dist-packages/pandas/io/common.py</span> in <span class="ni">get_handle</span><span class="nt">(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">854</span>         <span class="k">if</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span> <span class="ow">and</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">855</span>             <span class="c1"># Encoding</span>
<span class="ne">--&gt; </span><span class="mi">856</span>             <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">857</span>                 <span class="n">handle</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">858</span>                 <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;waterQuality1.csv&#39;
</pre></div>
</div>
</div>
</div>
<p>Kode di atas digunakan untuk membuka file csv dan menampilkan visual isi dari dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Banyaknya data : &quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Banyaknya kolom : &quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Banyaknya data :  7999
Banyaknya kolom :  21
</pre></div>
</div>
</div>
</div>
<p>fungs shape sendiri digunakan untuk mengetahui dimensi dari dataframe atau ukuran baris dan kolomnya.
df.shape[0]: Ini mencetak jumlah baris (data points) dalam DataFrame df. Dalam hal ini, jumlah barisnya adalah 7999.
df.shape[1]: Ini mencetak jumlah kolom (fitur atau variabel) dalam DataFrame df. Dalam hal ini, jumlah kolomnya adalah 21.
Dengan kata lain, DataFrame Anda memiliki 7999 baris dan 21 kolom.</p>
</section>
<section id="deskripsi-fitur-dataset">
<h2>Deskripsi Fitur Dataset<a class="headerlink" href="#deskripsi-fitur-dataset" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Aluminium</strong> : Merupakan kandungan aluminium dalam air. berbahaya jika lebih besar dari 2,8. kandungan aluminium yang berlebihan dapat menyebabkan masalah kesehatan, terutama pada sistem saraf.</p></li>
<li><p><strong>Ammonia</strong> : Kandungan ammonia (NH3) dalam air. Amonia adalah gas dengan bau yang tajam dan beracun dalam konsentrasi tinggi. berbahaya jika lebih besar dari 32,5. Kandungan ammonia yang tinggi dalam air dapat menyebabkan kerusakan organisme akuatik dan merusak kualitas air minum.</p></li>
<li><p><strong>Arsenic</strong> : Kandungan arsenik dalam air. Arsenic adalah unsur kimia dalam tabel periodik dengan simbol As dan nomor atom 33. Arsenic dapat ditemukan secara alami di dalam kerak bumi dan digunakan dalam berbagai aplikasi industri, termasuk pembuatan kayu tahan air. arsenic berbahaya jika lebih besar dari 0,01. Kandungan arsenik yang tinggi dalam air minum dapat menyebabkan keracunan dan meningkatkan risiko kanker.</p></li>
<li><p><strong>Barium</strong>: Kandungan barium dalam air. Barium adalah unsur kimia dengan simbol Ba dan nomor atom 56. Barium digunakan dalam industri minyak dan gas, serta dalam radiografi medis. berbahaya jika lebih besar dari 2. Pemaparan jangka panjang terhadap barium dapat menyebabkan kerusakan organ dalam tubuh manusia.</p></li>
<li><p><strong>Cadmium</strong> : Kandungan kadmium dalam air. Cadmium adalah unsur kimia dengan simbol Cd dan nomor atom 48. Cadmium digunakan dalam baterai, cat, dan plastik. berbahaya jika lebih besar dari 0,005. Pemaparan cadmium dapat menyebabkan masalah kesehatan serius, termasuk kerusakan ginjal dan kanker.</p></li>
<li><p><strong>Chloramine</strong> : Kandungan chloramine dalam air. Chloramine adalah senyawa kimia yang terbentuk dari klorin dan amonia. Ini digunakan sebagai desinfektan dalam air minum. berbahaya jika lebih besar dari 4. Paparan kloramine dalam jumlah yang tinggi dapat menyebabkan iritasi mata dan tenggorokan.</p></li>
<li><p><strong>Chromium</strong> : Kandungan kromium dalam air. berbahaya jika lebih besar dari 0,1. Pemaparan kromium VI dapat menyebabkan kerusakan paru-paru, penyakit pernapasan, dan kanker.</p></li>
<li><p><strong>Copper</strong> : Kandungan tembaga dalam air. Copper adalah unsur kimia dengan simbol Cu dan nomor atom 29. Copper digunakan dalam instalasi listrik, pipa, dan peralatan masak. berbahaya jika lebih besar dari 1,3. Kandungan tembaga yang berlebihan dalam air minum dapat menyebabkan gangguan pencernaan dan masalah hati.</p></li>
<li><p><strong>Fluoride</strong> : Kandungan fluoride dalam air. Fluoride adalah ion anorganik yang penting untuk kesehatan gigi. berbahaya jika lebih besar dari 1,5. konsumsi fluoride dalam jumlah yang berlebihan dapat menyebabkan masalah kesehatan gigi dan tulang.</p></li>
<li><p><strong>Bacteria</strong> : Indikator keberadaan bakteri dalam air. Bakteri adalah mikroorganisme yang dapat ditemukan dalam air. berbahaya jika lebih besar dari 0.</p></li>
<li><p><strong>Viruses</strong> : Indikator keberadaan virus dalam air. berbahaya jika lebih besar dari 0</p></li>
<li><p><strong>Lead</strong> : Kandungan timbal dalam air. Lead adalah logam berat yang dapat menyebabkan keracunan, terutama pada anak-anak. berbahaya jika lebih besar dari 0,015. Pemaparan timbal dapat menyebabkan kerusakan otak dan sistem saraf.</p></li>
<li><p><strong>Nitrates</strong> : Kandungan nitrat dalam air. Nitrates adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 10. Kandungan nitrates yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</p></li>
<li><p><strong>Nitrites</strong> : Kandungan nitrit dalam air. nitrites adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 1. Kandungan nitrites yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</p></li>
<li><p><strong>Mercury</strong> : Kandungan merkuri dalam air. Mercury adalah logam berat yang dapat mengakumulasi dalam organisme hidup dan menyebabkan keracunan. berbahaya jika lebih besar dari 0,002. Pemaparan merkuri dapat merusak otak, ginjal, dan sistem saraf.</p></li>
<li><p><strong>Perchlorate</strong> : Kandungan perchlorate dalam air. Perchlorate adalah senyawa kimia yang digunakan dalam bahan peledak dan propelan roket. Pemaparan perchlorate dapat mengganggu fungsi tiroid. berbahaya jika lebih besar dari 56</p></li>
<li><p><strong>Radium</strong> : Kandungan radium dalam air. Radium adalah unsur radioaktif yang dapat ditemukan secara alami dalam tanah dan air. Paparan radium dapat meningkatkan risiko kanker. berbahaya jika lebih besar dari 5</p></li>
<li><p><strong>Selenium</strong> : Kandungan selenium dalam air. berbahaya jika lebih besar dari 0,5. konsumsi selenium yang berlebihan dapat menyebabkan masalah kesehatan, termasuk kerusakan saraf.</p></li>
<li><p><strong>Silver</strong> : Kandungan perak dalam air. berbahaya jika lebih besar dari 0,1. Konsumsi perak dalam jumlah yang berlebihan dapat menyebabkan argyria, kondisi di mana kulit manusia berubah menjadi warna biru keabu-abuan.</p></li>
<li><p><strong>Uranium</strong> : Kandungan uranium dalam air. Uranium adalah unsur radioaktif yang dapat ditemukan secara alami dalam batuan dan air. Paparan uranium dapat meningkatkan risiko kanker dan masalah ginjal. berbahaya jika lebih besar dari 0,3</p></li>
<li><p><strong>Is_safe</strong> : Kolom ini adalah label atau target variabel yang menunjukkan apakah sampel air tersebut aman untuk dikonsumsi atau tidak. class attribute {0 - not safe, 1 - safe}</p></li>
</ol>
<p>fitur di atas ini mencerminkan kandungan berbagai mikroorganisme dalam air. Dalam setiap fitur atau kandungan yang ada dalam air tersebut memiliki batasan aman. jika kandungan mikroorganisme melebihi nilai-nilai batasan ini, air dianggap tidak aman untuk konsumsi manusia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;, &#39;is_safe&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>fungsi columns digunakan untuk menampilkan nama-nama kolom pada dataframe. yang mana dataset water quality ini terdiri dari 21 kolom, yakni aluminium, ammonia, arsenic, barium, cadmium, chloramine, chromium, copper, flouride, bacteria, viruses, lead, nitrates, nitrites, mercury, perchlorate, radium, selenium, silver, uranium, dan is_safe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>viruses</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
      <td>7999.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.666158</td>
      <td>0.161445</td>
      <td>1.567715</td>
      <td>0.042806</td>
      <td>2.176831</td>
      <td>0.247226</td>
      <td>0.805857</td>
      <td>0.771565</td>
      <td>0.319665</td>
      <td>0.328583</td>
      <td>0.099450</td>
      <td>9.818822</td>
      <td>1.329961</td>
      <td>0.005194</td>
      <td>16.460299</td>
      <td>2.920548</td>
      <td>0.049685</td>
      <td>0.147781</td>
      <td>0.044673</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.265145</td>
      <td>0.252590</td>
      <td>1.216091</td>
      <td>0.036049</td>
      <td>2.567027</td>
      <td>0.270640</td>
      <td>0.653539</td>
      <td>0.435373</td>
      <td>0.329485</td>
      <td>0.378096</td>
      <td>0.058172</td>
      <td>5.541331</td>
      <td>0.573219</td>
      <td>0.002967</td>
      <td>17.687474</td>
      <td>2.323009</td>
      <td>0.028770</td>
      <td>0.143551</td>
      <td>0.026904</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.040000</td>
      <td>0.030000</td>
      <td>0.560000</td>
      <td>0.008000</td>
      <td>0.100000</td>
      <td>0.050000</td>
      <td>0.090000</td>
      <td>0.405000</td>
      <td>0.000000</td>
      <td>0.002000</td>
      <td>0.048000</td>
      <td>5.000000</td>
      <td>1.000000</td>
      <td>0.003000</td>
      <td>2.170000</td>
      <td>0.820000</td>
      <td>0.020000</td>
      <td>0.040000</td>
      <td>0.020000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.070000</td>
      <td>0.050000</td>
      <td>1.190000</td>
      <td>0.040000</td>
      <td>0.530000</td>
      <td>0.090000</td>
      <td>0.750000</td>
      <td>0.770000</td>
      <td>0.220000</td>
      <td>0.008000</td>
      <td>0.102000</td>
      <td>9.930000</td>
      <td>1.420000</td>
      <td>0.005000</td>
      <td>7.740000</td>
      <td>2.410000</td>
      <td>0.050000</td>
      <td>0.080000</td>
      <td>0.050000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.280000</td>
      <td>0.100000</td>
      <td>2.480000</td>
      <td>0.070000</td>
      <td>4.240000</td>
      <td>0.440000</td>
      <td>1.390000</td>
      <td>1.160000</td>
      <td>0.610000</td>
      <td>0.700000</td>
      <td>0.151000</td>
      <td>14.610000</td>
      <td>1.760000</td>
      <td>0.008000</td>
      <td>29.480000</td>
      <td>4.670000</td>
      <td>0.070000</td>
      <td>0.240000</td>
      <td>0.070000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5.050000</td>
      <td>1.050000</td>
      <td>4.940000</td>
      <td>0.130000</td>
      <td>8.680000</td>
      <td>0.900000</td>
      <td>2.000000</td>
      <td>1.500000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.200000</td>
      <td>19.830000</td>
      <td>2.930000</td>
      <td>0.010000</td>
      <td>60.010000</td>
      <td>7.990000</td>
      <td>0.100000</td>
      <td>0.500000</td>
      <td>0.090000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Fungsi describe() digunakan untuk menampilkan statistik deskriptif dari data frame atau series. Output dari fungsi ini berisi rangkuman central tendency dan sebaran dari dataset. Fungsi describe() membantu kita untuk mendapatkan overview dari dataset. Di bawah ini adalah penjelasan hasil yang diberikan:</p>
<ul class="simple">
<li><p>Count (Jumlah): Menunjukkan jumlah data yang ada dalam setiap kolom. Misalnya, pada kolom “aluminium”, terdapat 7999 data.</p></li>
<li><p>Mean (Rata-rata): Menunjukkan nilai rata-rata dari setiap kolom. Misalnya, rata-rata kandungan aluminium adalah sekitar 0.666158.</p></li>
<li><p>Std (Standar Deviasi): Menunjukkan sejauh mana nilai-nilai dalam kolom tersebar dari rata-rata. Semakin tinggi standar deviasi, semakin besar variabilitasnya dari rata-rata. Misalnya, standar deviasi kandungan aluminium adalah sekitar 1.265145.</p></li>
<li><p>Min (Minimum): Menunjukkan nilai terkecil dalam setiap kolom. Misalnya, nilai minimum kandungan arsenik adalah 0.0.</p></li>
<li><p>25% (Kuartil Pertama): Menunjukkan nilai yang membagi 25% data terendah dari nilai-nilai lainnya. Misalnya, pada kolom “aluminium”, 25% data berada di bawah 0.040000.</p></li>
<li><p>50% (Median atau Kuartil Kedua): Menunjukkan nilai yang membagi dataset menjadi dua bagian setara, atau median. Misalnya, median kandungan aluminium adalah 0.070000.</p></li>
<li><p>75% (Kuartil Ketiga): Menunjukkan nilai yang membagi 75% data terendah dari nilai-nilai lainnya. Misalnya, pada kolom “aluminium”, 75% data berada di bawah 0.280000.</p></li>
<li><p>Max (Maksimum): Menunjukkan nilai tertinggi dalam setiap kolom. Misalnya, nilai maksimum kandungan aluminium adalah 5.050000.</p></li>
</ul>
</section>
<section id="deskripsi-tipe-data-fitur">
<h2>Deskripsi Tipe Data Fitur<a class="headerlink" href="#deskripsi-tipe-data-fitur" title="Permalink to this heading">#</a></h2>
<p>Berikut adalah analisis tipe data untuk setiap kolom beserta alasannya:</p>
<ol class="arabic simple">
<li><p>aluminium: Tipe data rasio. Kandungan aluminium dalam air memiliki nol yang bermakna, dan perbandingan antara dua nilai memiliki arti yang jelas (misalnya, 2 kali lipat).</p></li>
<li><p>ammonia: Tipe data rasio. Kandungan ammonia dalam air juga memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>arsenic: Tipe data rasio. Kandungan arsenik dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>barium: Tipe data rasio. Kandungan barium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>cadmium: Tipe data rasio. Kandungan cadmium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chloramine: Tipe data rasio. Kandungan chloramine dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chromium: Tipe data rasio. Kandungan chromium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>copper: Tipe data rasio. Kandungan copper dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>flouride: Tipe data rasio. Kandungan flouride dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>bacteria: Tipe data rasio. Kandungan bakteri dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>viruses: Tipe data rasio. Kandungan virus dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>lead: Tipe data rasio. Kandungan lead dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrates: Tipe data rasio. Kandungan nitrates dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrites: Tipe data rasio. Kandungan nitrites dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>mercury: Tipe data rasio. Kandungan mercury dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>perchlorate: Tipe data rasio. Kandungan perchlorate dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>radium: Tipe data rasio. Kandungan radium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>selenium: Tipe data rasio. Kandungan selenium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>silver: Tipe data rasio. Kandungan silver dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>uranium: Tipe data rasio. Kandungan uranium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>is_safe: Tipe data nominal. Variabel target ini merupakan label kategori yang menunjukkan apakah air layak diminum atau tidak. Ini merupakan tipe data kategorikal dengan dua kategori yang bersifat nominal.</p></li>
</ol>
</section>
<section id="identifikasi-missing-value">
<h2>Identifikasi Missing Value<a class="headerlink" href="#identifikasi-missing-value" title="Permalink to this heading">#</a></h2>
<p>(Dataset ini memiliki 3 missing value pada kolom amonia dan is_safe)
penjelasannya sebagai berikut :</p>
<p>Identifikasi missing value adalah proses mengenali dan menentukan lokasi di mana nilai-nilai yang hilang (missing value) terdapat dalam dataset. untuk mencari missing value kita bisa menggunakan fungsi info(). Fungsi info() digunakan untuk menampilkan informasi detail tentang dataframe, seperti jumlah baris data, nama-nama kolom berserta jumlah data dan tipe datanya, dan sebagainya. Dimana didapat bahwa dataset tersebut nampaknya tidak memiliki nilai yang missing karena nilai non-null setiap kolomnya sebanyak 7999 sama dengan jumlah dataset sebenarnya. akan tetapi perlu di telisik lebih dalam karena bisa jadi valuenya terdapat kerusakan seperti yang awalnya berupa angka, akan tetapi berubah menjadi stringg atau object, dimana itu terdeteksi pada kolom amonia dan is_safe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 7999 entries, 0 to 7998
Data columns (total 21 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   aluminium    7999 non-null   float64
 1   ammonia      7999 non-null   object 
 2   arsenic      7999 non-null   float64
 3   barium       7999 non-null   float64
 4   cadmium      7999 non-null   float64
 5   chloramine   7999 non-null   float64
 6   chromium     7999 non-null   float64
 7   copper       7999 non-null   float64
 8   flouride     7999 non-null   float64
 9   bacteria     7999 non-null   float64
 10  viruses      7999 non-null   float64
 11  lead         7999 non-null   float64
 12  nitrates     7999 non-null   float64
 13  nitrites     7999 non-null   float64
 14  mercury      7999 non-null   float64
 15  perchlorate  7999 non-null   float64
 16  radium       7999 non-null   float64
 17  selenium     7999 non-null   float64
 18  silver       7999 non-null   float64
 19  uranium      7999 non-null   float64
 20  is_safe      7999 non-null   object 
dtypes: float64(19), object(2)
memory usage: 1.3+ MB
</pre></div>
</div>
</div>
</div>
<p>Kita akan mengecek apakah sebuah data mengandung Pesan “#NUM!”. #NUM! mungkin muncul karena adanya kesalahan atau format yang tidak tepat dalam dataset, terutama pada kolom yang seharusnya berisi nilai numerik. Tanda ini seringkali menunjukkan bahwa suatu sel atau entri dalam dataset tidak dapat diuraikan sebagai nilai numerik yang valid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung apakah ada nilai &#39;#NUM!&#39; dalam setiap kolom</span>
<span class="n">contains_num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="s1">&#39;#NUM!&#39;</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apakah ada nilai &#39;#NUM!&#39; dalam setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">contains_num</span><span class="o">.</span><span class="n">any</span><span class="p">())</span>

<span class="c1"># Menghitung jumlah nilai &#39;#NUM!&#39; untuk setiap kolom</span>
<span class="n">num_count_per_column</span> <span class="o">=</span> <span class="n">contains_num</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah nilai &#39;#NUM!&#39; untuk setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">num_count_per_column</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Apakah ada nilai &#39;#NUM!&#39; dalam setiap kolom:
aluminium      False
ammonia         True
arsenic        False
barium         False
cadmium        False
chloramine     False
chromium       False
copper         False
flouride       False
bacteria       False
viruses        False
lead           False
nitrates       False
nitrites       False
mercury        False
perchlorate    False
radium         False
selenium       False
silver         False
uranium        False
is_safe         True
dtype: bool
Jumlah nilai &#39;#NUM!&#39; untuk setiap kolom:
aluminium      0
ammonia        3
arsenic        0
barium         0
cadmium        0
chloramine     0
chromium       0
copper         0
flouride       0
bacteria       0
viruses        0
lead           0
nitrates       0
nitrites       0
mercury        0
perchlorate    0
radium         0
selenium       0
silver         0
uranium        0
is_safe        3
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Kode di atas ini digunakan untuk mengakumulasi dengan melakukan pengecekan apakah terdapat nilai yang hilang (NaN) dalam kolom yang ada dalam DataFrame (df).</p>
<ul class="simple">
<li><p>Fungsi eq
(singkatan dari “equal”) pada Pandas digunakan untuk membandingkan elemen-elemen dalam suatu DataFrame atau Series dengan nilai tertentu dan mengembalikan DataFrame atau Series baru yang berisi nilai True jika elemennya sama dengan nilai yang dibandingkan, dan False jika tidak.</p></li>
<li><p>Fungsi any()
fungsi any() pada Pandas digunakan untuk menentukan apakah setidaknya satu elemen dalam suatu DataFrame atau Series memiliki nilai True. Jika ada setidaknya satu nilai True, maka fungsi any() akan mengembalikan True; sebaliknya, jika semua nilai adalah False, maka akan mengembalikan False.</p></li>
<li><p>fungsi sum()
fungsi sum() pada pandas digunakan untuk menjumlahkan suatu data, dimana fungsi ini digunakan untuk menghitung jumlah nilai True (jumlah nilai ‘#NUM!’) dalam setiap kolom dan menyimpannya dalam suatu variable untuk kemudian ditampilkan.</p></li>
</ul>
<p>Berdasarkan identifikasi lebih dalam maka didapati nilai yang hilang berupa #NUM! Dalam dataset water quality ini memiliki 3 missing value pada kolom amonia dan is_safe.</p>
</section>
<section id="identifikasi-data-duplicated">
<h2>Identifikasi Data Duplicated<a class="headerlink" href="#identifikasi-data-duplicated" title="Permalink to this heading">#</a></h2>
<p>Identifikasi data duplikat merujuk pada proses menemukan dan menandai baris atau entri dalam dataset yang memiliki nilai yang sama di semua kolomnya. Dengan kata lain, data duplikat adalah duplikat persis dari baris lainnya dalam dataset. Dalam dataset water Quality ini tidak ditemukannya data duplikat.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jumlah_duplikat</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Menampilkan jumlah data yang duplikat</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang duplikat:&quot;</span><span class="p">,</span> <span class="n">jumlah_duplikat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data yang duplikat: 0
</pre></div>
</div>
</div>
</div>
<p>Kode diatas yakni digunakan untuk mengidentifikasi dan menghitung jumlah data duplikat dalam DataFrame (df). Menggunakan metode duplicated() untuk menghasilkan keterangan boolean yang menunjukkan apakah setiap baris dalam DataFrame adalah duplikat dari baris sebelumnya atau tidak (True atau False). Kemudian, metode sum() digunakan untuk menghitung jumlah total nilai True, yang merupakan jumlah total data duplikat.
Dalam dataset saya, tidak ada data yang mengalami duplikasi data.</p>
<p>Contoh deteksi duplikat data :</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>A</p></th>
<th class="head"><p>B</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>apple</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>banana</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>apple</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>banana</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>orange</p></td>
</tr>
</tbody>
</table>
<p>Baris-baris yang merupakan duplikat:</p>
<ul class="simple">
<li><p>0    False</p></li>
<li><p>1    False</p></li>
<li><p>2    False</p></li>
<li><p>3     True</p></li>
<li><p>4    False</p></li>
</ul>
</section>
<section id="identifikasi-sebaran-kelas-data">
<h2>Identifikasi Sebaran Kelas Data<a class="headerlink" href="#identifikasi-sebaran-kelas-data" title="Permalink to this heading">#</a></h2>
<p>identifikasi ini digunakan untuk melihat sejauh mana perbedaan jumlah kedua kelas yakni kelas 0 atau tidak aman, dan kelas 1 atau aman. Dalam dataset Water Quality ini mengalamni unbalance data, dimana terdapat perbedaan yang cukup signifikan dalam jumlah data tiap kelasnya. Data dengan kelas 0 atau tidak aman berjumlah 7084 berbanding cukup jauh dengan data dengan kelas 1 yang hanya berkisar 912 data saja. Oleh karena itu, perlu dilakukan pre-processing untuk menyamaratakan jumlah data setiap kelasnya.</p>
<p>Menurut He dan Edwardo (2009) sebuah himpunan data dikatakan imbalanced jika terdapat salah satu kelas yang direpresentasikan
dalam jumlah yang tidak sebanding dengan kelas yang lain. Kondisi imbalanced data menjadi masalah dalam klasifikasi karena classifier learning akan condong memprediksi ke kelas data yang banyak (mayoritas) dibanding dengan kelas yang sedikit (minoritas). Akibatnya, dihasilkan akurasi prediksi yang baik terhadap kelas data training yang banyak (kelas mayoritas) sedangkan untuk kelas data training yang sedikit (kelas minoritas) akan dihasilkan akurasi prediksi yang buruk.</p>
<p>Imbalanced data dapat diatasi dengan beberapa cara, antara lain dengan pengambilan sampel pada setiap kelas dan strategi sampling seperti oversampling atau undersampling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">is_safe</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1&#39; &#39;0&#39; &#39;#NUM!&#39;]
0        7084
1         912
#NUM!       3
Name: is_safe, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Menggunakan seaborn untuk membuat countplot</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>

<span class="c1"># Menambahkan label pada sumbu y</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Jumlah Data&#39;</span><span class="p">)</span>

<span class="c1"># Menambahkan judul plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribusi Kelas&#39;</span><span class="p">)</span>

<span class="c1"># Menampilkan jumlah data untuk masing-masing kelas di atas batangnya</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">patches</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">get_height</span><span class="p">()),</span>
                <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">)</span>

<span class="c1"># Menampilkan plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa38c796e21a70ed3186e562e7bc691be929aec28bd3c4d1e901aaff6e35fc5c.png" src="_images/aa38c796e21a70ed3186e562e7bc691be929aec28bd3c4d1e901aaff6e35fc5c.png" />
</div>
</div>
<p>Kode diatas menggunakan seaborn dan matplotlib untuk membuat countplot dari kolom ‘is_safe’ dalam DataFrame df. Hasilnya adalah visualisasi distribusi kelas ‘is_safe’ dengan jumlah data di setiap kategori.</p>
</section>
<section id="identifikasi-outlier">
<h2>Identifikasi Outlier<a class="headerlink" href="#identifikasi-outlier" title="Permalink to this heading">#</a></h2>
<p>Identifikasi Outlier kali ini menggunakan Metode Local Outlier Factor. Local Outlier Factor (LOF) adalah metode yang digunakan untuk mendeteksi outlier dalam dataset. Data dalam dataset water quality yang mengalami outlier adalah sebanyak 1999 data.</p>
<p>Metode Local Outlier Factor (LOF) membandingkan kerapatan suatu titik data dengan kerapatan titik-titik di sekitarnya. LOF mengukur sejauh mana suatu titik data dianggap anomali atau outlier berdasarkan perbedaan kerapatan. Metode ini dikembangkan oleh Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, dan Jörg Sander pada tahun 2000. <a href='https://en.wikipedia.org/wiki/Local_outlier_factor'>Sumber</a></p>
<p>Berikut adalah langkah-langkah Local Outlier Factor (LOF):</p>
<ol class="arabic simple">
<li><p>Hitung jarak antar titik dan tetangga</p></li>
</ol>
<ul class="simple">
<li><p>Rumus jarak euclidean antara dua titik p dan 1 dalam dimensi n: \begin{equation}
\text{Euclidean Distance} (P, Q) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}
\end{equation}
\begin{equation}
\text{Euclidean Distance} (P, Q) = \sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2}
\end{equation}</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Hitung kepadatan lokasi</p></li>
</ol>
<ul class="simple">
<li><p>Kepadatan lokal suatu titik p:
\begin{equation}
\text{Density}_p = \frac{1}
\end{equation}
\begin{equation}

\end{equation}</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Hitung Local Reachability Density (LRD)</p></li>
</ol>
<ul class="simple">
<li><p>Local Reachability Density (LRD) suatu titik p:
\begin{equation}
\text{LRD}_p = \left(\text{Density}_p\right)^{\frac{1}{\alpha}}
\end{equation}
di mana α adalah parameter untuk menyesuaikan sensitivitas terhadap fluktuasi kecil dalam kepadatan.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Hitung Local Outlier Factor (LOF)</p></li>
</ol>
<ul class="simple">
<li><p>Local Outlier Factor (LOF) suatu titik p:
\begin{equation}
\text{LOF}_p = \frac{\left|\text{Neighbors}<em>p\right|}{\sum</em>{o \in \text{Neighbors}_p} \frac{\text{LRD}_o}{\text{LRD}_p}}
\end{equation}
di mana Neighborsp adalah himpunan tetangga dari titik p.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Identifikasi Outlier: Tentukan threshold, dan labeli titik-titik yang memiliki LOF di atas threshold sebagai outlier. Pada umumnya, jika
LOF(p) &gt; Threshold, maka titik p dianggap sebagai outlier.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>

<span class="c1"># Mengganti &#39;#NUM!&#39; dengan NaN dan mengonversi kolom ke tipe float</span>
<span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;#NUM!&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

<span class="c1"># Filter DataFrame untuk nilai yang bukan NaN (numerik)</span>
<span class="n">df_numeric</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Contamination values yang ingin diuji</span>
<span class="n">contamination_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]</span>

<span class="c1"># Inisialisasi variabel untuk menyimpan hasil terbaik</span>
<span class="n">max_outliers</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;contamination&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>

<span class="c1"># Loop untuk nilai n_neighbors dari 1 hingga 50</span>
<span class="k">for</span> <span class="n">n_neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">51</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">contamination</span> <span class="ow">in</span> <span class="n">contamination_values</span><span class="p">:</span>
        <span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="n">contamination</span><span class="p">)</span>
        <span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df_numeric</span><span class="p">)</span>
        <span class="n">num_outliers</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">outlier_labels</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Menghitung jumlah outlier yang dideteksi</span>

        <span class="c1"># Memperbarui hasil terbaik jika ditemukan jumlah outlier yang lebih banyak</span>
        <span class="k">if</span> <span class="n">num_outliers</span> <span class="o">&gt;</span> <span class="n">max_outliers</span><span class="p">:</span>
            <span class="n">max_outliers</span> <span class="o">=</span> <span class="n">num_outliers</span>
            <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_neighbors</span>
            <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;contamination&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">contamination</span>

<span class="c1"># Mencetak hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parameter terbaik:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data outlier :&quot;</span><span class="p">,</span> <span class="n">max_outliers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data tanpa outlier :&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="n">max_outliers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;n_neighbors =&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;contamination =&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;contamination&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Lenovo\anaconda3\Lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores &lt; 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
  File &quot;C:\Users\Lenovo\anaconda3\Lib\site-packages\joblib\externals\loky\backend\context.py&quot;, line 282, in _count_physical_cores
    raise ValueError(f&quot;found {cpu_count_physical} physical cores &lt; 1&quot;)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter terbaik:
Jumlah data outlier : 1999
Jumlah data tanpa outlier : 6000
n_neighbors = 1
contamination = 0.25
</pre></div>
</div>
</div>
</div>
<p>Pada kode di atas, saya menerapkan grid search untuk mencari parameter yang bagus guna mendeteksi outlier, dimana parameter yang terpilih yakni dengan n_neighbors 1 dan contaminationsnya 0,25</p>
</section>
<section id="eksplorasi-data">
<h2>Eksplorasi Data<a class="headerlink" href="#eksplorasi-data" title="Permalink to this heading">#</a></h2>
<p>Pada eksplorasi data kali ini saya akan menampilkan data ke dalam bentuk grafik-grafik seperti histogram, dan matrix. Visualisasi ini agar memudahkan untuk mengambil informasi penting dari sebuah data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca data dari file csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li></li>
</ul>
<section id="histogram-sebaran-frekuensi-data-setiap-kolom">
<h3>Histogram Sebaran Frekuensi Data Setiap Kolom<a class="headerlink" href="#histogram-sebaran-frekuensi-data-setiap-kolom" title="Permalink to this heading">#</a></h3>
</section>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#distribution data</span>
<span class="n">df</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e6ed649ca1013b127e9dd809d4080306b55488e00b84defb716ec90d923fe206.png" src="_images/e6ed649ca1013b127e9dd809d4080306b55488e00b84defb716ec90d923fe206.png" />
</div>
</div>
<p>Kode diatas bertujuan untuk memberikan visualisasi distribusi data dari dataframe df menggunakan histogram. Histogram adalah grafik yang membagi rentang data ke dalam interval dan menghitung jumlah data yang jatuh dalam setiap interval tersebut. Ini membantu untuk memahami pola distribusi data dan melihat sebaran nilai-nilai dalam dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">)</span>

<span class="c1"># Plot histograms for the distribution of all columns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">data_columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">data_columns</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>

<span class="c1"># Adjust the number of rows and columns in the subplot grid for better visualization</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_columns</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_columns</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Distribusi kolom </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Kepadatan&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Distribusi Data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e82fa985081f719d2c4244b97faccec4aa14029c83f9fb2b5e89a59bf670aec9.png" src="_images/e82fa985081f719d2c4244b97faccec4aa14029c83f9fb2b5e89a59bf670aec9.png" />
</div>
</div>
<p>Kode di atas mengatur gaya plot, kemudian memplot histogram untuk distribusi semua kolom pada DataFrame. Setiap subplot menunjukkan distribusi nilai dari satu kolom, dan garis halus (kernel density estimation) ditambahkan untuk memberikan representasi kepadatan distribusi data.</p>
<ul class="simple">
<li></li>
</ul>
<section id="matrix-korelasi">
<h3>Matrix Korelasi<a class="headerlink" href="#matrix-korelasi" title="Permalink to this heading">#</a></h3>
</section>
<p>Kode berikut dibawah ini menghasilkan sebuah matriks korelasi dengan menggunakan fungsi corr() dari pandas pada DataFrame df. Matriks korelasi ini merepresentasikan hubungan linier antara semua pasangan variabel dalam dataset. Setiap sel dalam matriks menunjukkan nilai korelasi antara dua variabel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Plot of Water Quality Parameters&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Lenovo\AppData\Local\Temp\ipykernel_13180\1987230932.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = df.corr()
</pre></div>
</div>
<img alt="_images/8b026de9615807166b7b24779b8d10625b081428f22aae2175ce74b7fee33d59.png" src="_images/8b026de9615807166b7b24779b8d10625b081428f22aae2175ce74b7fee33d59.png" />
</div>
</div>
<p>Cara membaca matriks korelasi:</p>
<p>Skala Nilai Korelasi:</p>
<ul class="simple">
<li><p>1.0: Korelasi sempurna positif. Artinya, jika satu variabel naik, yang lain juga naik secara linear.</p></li>
<li><p>-1.0: Korelasi sempurna negatif. Artinya, jika satu variabel naik, yang lain turun secara linear.</p></li>
<li><p>0.0: Tidak ada korelasi linier antara variabel tersebut.</p></li>
</ul>
<p>Warna Sel pada Heatmap digunakan untuk memvisualisasikan matriks korelasi. Sel-sel dengan warna yang lebih terang atau lebih gelap menunjukkan nilai korelasi yang lebih tinggi, sementara warna yang lebih netral menunjukkan korelasi yang lebih rendah.</p>
<ul class="simple">
<li></li>
</ul>
<section id="diagram-lingkaran-perbandingan-jumlah-data-kelas">
<h3>Diagram Lingkaran perbandingan jumlah data kelas<a class="headerlink" href="#diagram-lingkaran-perbandingan-jumlah-data-kelas" title="Permalink to this heading">#</a></h3>
</section>
<p>ini digunakan untuk menggambarkan persentasi perbandingan distribusi data setiap kelas yakni kelas 0 (tidak aman) dan kelas 1 (aman)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Menghapus baris dengan nilai &#39;#NUM!&#39;</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span> <span class="o">!=</span> <span class="s1">&#39;#NUM!&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Menghitung jumlah data untuk setiap kelas</span>
<span class="n">class_counts</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Membuat plot pie chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pie</span><span class="p">(</span><span class="n">class_counts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">class_counts</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">autopct</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%1.1f%%</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">startangle</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">,</span> <span class="s1">&#39;lightcoral&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribusi Kelas (is_safe)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/898b31555ab01fecdd6a3d23b3465fb0b3453b7225f375afd6dc45b69ce389cd.png" src="_images/898b31555ab01fecdd6a3d23b3465fb0b3453b7225f375afd6dc45b69ce389cd.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pre-procesing">
<h1>Pre-Procesing<a class="headerlink" href="#pre-procesing" title="Permalink to this heading">#</a></h1>
<p>Preprocessing (pra-pemrosesan) adalah tahap dalam analisis data yang bertujuan untuk membersihkan, mengorganisir, dan menyesuaikan data sehingga dapat digunakan secara efektif untuk pemodelan atau analisis lebih lanjut.</p>
<section id="handling-missing-data">
<h2>Handling Missing Data<a class="headerlink" href="#handling-missing-data" title="Permalink to this heading">#</a></h2>
<p>Mengidentifikasi dan menangani nilai-nilai yang hilang dalam dataset.
Cara penanganannya bisa berupa menghapus baris/kolom yang mengandung nilai yang hilang atau mengisi nilai yang hilang dengan suatu nilai (misalnya, rata-rata, median, atau nilai yang paling sering muncul).</p>
<p>Sebelumnya telah teridentifikasi bahwa dataset water quality ini memiliki 3 nilai yang hilang atau berupa #NUM! pada kolom amonia dan is_safe, selain itu kolom tersebut yang masih berupa object bukan numeric. oleh karena itu perlu dilakukan penanganan dengan cara menghapus kolom yang memiliki nilai yang hilang tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca data dari file csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;waterQuality1.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Pertama kita ganti nilai #NUM! menjadi NaN. Fungsi replace() digunakan untuk mengganti sebuah nilai pada dataframe. Misalnya disini kita mengganti nilai #NUM! yang ada di dataframe dengan NaN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;#NUM!&quot;</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">NA</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Selanjutnya menseleksi dataframe yang kolom amonia-nya tidak mengandung missing value atau NaN. artinya kolom yang hilang tadi dilakukan penghapusan data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ammonia&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>
</pre></div>
</div>
</div>
</div>
<p>Lalu dilakukan penggantian tipe data kolom amonia dan is_safe yang sebelumnya berupa object atau string menjadi tipe data numeric menggunakan fungsi to_numeric().</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ammonia&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ammonia&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>selanjutnya dilakukan pengecekan kembali terhadap dataset apakah missing value telah dihapus atau belum, dan melihat tipe data dari setiap kolomnya apakah sudah menjadi numeric semua.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung apakah ada nilai yang hilang dalam setiap kolom</span>
<span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()</span>

<span class="c1"># Menampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Apakah ada nilai yang hilang dalam setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_values</span><span class="p">)</span>

<span class="n">nan_kolom</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah nilai yang hilang (NA) untuk setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nan_kolom</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Apakah ada nilai yang hilang dalam setiap kolom:
aluminium      False
ammonia        False
arsenic        False
barium         False
cadmium        False
chloramine     False
chromium       False
copper         False
flouride       False
bacteria       False
viruses        False
lead           False
nitrates       False
nitrites       False
mercury        False
perchlorate    False
radium         False
selenium       False
silver         False
uranium        False
is_safe        False
dtype: bool
Jumlah nilai yang hilang (NA) untuk setiap kolom:
aluminium      0
ammonia        0
arsenic        0
barium         0
cadmium        0
chloramine     0
chromium       0
copper         0
flouride       0
bacteria       0
viruses        0
lead           0
nitrates       0
nitrites       0
mercury        0
perchlorate    0
radium         0
selenium       0
silver         0
uranium        0
is_safe        0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
Int64Index: 7996 entries, 0 to 7998
Data columns (total 21 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   aluminium    7996 non-null   float64
 1   ammonia      7996 non-null   float64
 2   arsenic      7996 non-null   float64
 3   barium       7996 non-null   float64
 4   cadmium      7996 non-null   float64
 5   chloramine   7996 non-null   float64
 6   chromium     7996 non-null   float64
 7   copper       7996 non-null   float64
 8   flouride     7996 non-null   float64
 9   bacteria     7996 non-null   float64
 10  viruses      7996 non-null   float64
 11  lead         7996 non-null   float64
 12  nitrates     7996 non-null   float64
 13  nitrites     7996 non-null   float64
 14  mercury      7996 non-null   float64
 15  perchlorate  7996 non-null   float64
 16  radium       7996 non-null   float64
 17  selenium     7996 non-null   float64
 18  silver       7996 non-null   float64
 19  uranium      7996 non-null   float64
 20  is_safe      7996 non-null   int64  
dtypes: float64(20), int64(1)
memory usage: 1.3 MB
</pre></div>
</div>
</div>
</div>
<p>Melalui pengecekan ini, didapati bahwa missing value telah dihapus, dan tipe data kolom sudah menjadi numeric dan bukan object. Selanjutnya kita bisa simpang hasil data yang sudah tidak ada missing value dengan nama datanomissing.csv</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;datanomissing.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-cleaning">
<h2>Data Cleaning<a class="headerlink" href="#data-cleaning" title="Permalink to this heading">#</a></h2>
<p>Data cleaning kali ini akan Mendeteksi dan mengatasi noise atau outlier dalam data. Noise dapat muncul sebagai nilai yang ekstrim atau tidak sesuai dengan distribusi umum data. Dalam data cleaning ini saya akan menggunakan metode Local Outlier Factor. Didapati pada data understanding dimana outlier terdeteksi sebanyak 1999 data dan perlu dilakukan penghapusan data tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca data dari file csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datanomissing.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Kita coba gambarkan data dan sebarannya melalui BoxPlot untuk mengetahui seperti apa data outlier dalam setiap kolom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a list of numerical features and plot them</span>
<span class="n">list_of_num_features</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>  <span class="c1"># DataFrame of numerical features</span>
<span class="n">palette_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#E68753&#39;</span><span class="p">,</span> <span class="s1">&#39;#409996&#39;</span><span class="p">]</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;axes.facecolor&#39;</span><span class="p">:</span><span class="s1">&#39;#ECECEC&#39;</span><span class="p">})</span>

<span class="c1"># Mengatur tata letak subplot</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_cols</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Flatten array of subplots for ease of indexing</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">list_of_num_features</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>  <span class="c1"># Mengambil subplot yang sesuai</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">palette_features</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>

<span class="c1"># Sembunyikan subplot yang tidak digunakan</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_of_num_features</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">num_rows</span> <span class="o">*</span> <span class="n">num_cols</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">delaxes</span><span class="p">(</span><span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="c1"># Atur tata letak dan tampilkan plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6df3c669504c7def6f0a244255d4cd12fc2519056ab7ce82b73cc6c6cd4587dc.png" src="_images/6df3c669504c7def6f0a244255d4cd12fc2519056ab7ce82b73cc6c6cd4587dc.png" />
</div>
</div>
<p>Kita coba kembali menggunakan local outlier factor untuk mendeteksi jumlah data outlier di dalam data menggunakan fungsi LocalOutlierFactor dengan parameter n_neigbors yakni 1 dan contamination yakni 0,25. Parameter ini didapat dari pencarian menggunakan grid search pada data undestanding di atas.
Selanjutnya baris data yang terdeteksi sebagai outlier akan diberikan label -1 sedangkan yang bukan outlier akan diberi label 1</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menggunakan Local Outlier Factor</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Outlier&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
      <th>Outlier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>7991</th>
      <td>0.05</td>
      <td>7.78</td>
      <td>0.00</td>
      <td>1.95</td>
      <td>0.040</td>
      <td>0.10</td>
      <td>0.03</td>
      <td>0.03</td>
      <td>1.37</td>
      <td>0.00</td>
      <td>...</td>
      <td>14.29</td>
      <td>1.00</td>
      <td>0.005</td>
      <td>3.57</td>
      <td>2.13</td>
      <td>0.09</td>
      <td>0.06</td>
      <td>0.03</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7992</th>
      <td>0.05</td>
      <td>24.22</td>
      <td>0.02</td>
      <td>0.59</td>
      <td>0.010</td>
      <td>0.45</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>1.48</td>
      <td>0.00</td>
      <td>...</td>
      <td>10.27</td>
      <td>1.00</td>
      <td>0.001</td>
      <td>1.48</td>
      <td>1.11</td>
      <td>0.09</td>
      <td>0.10</td>
      <td>0.08</td>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>7993</th>
      <td>0.09</td>
      <td>6.85</td>
      <td>0.00</td>
      <td>0.61</td>
      <td>0.030</td>
      <td>0.05</td>
      <td>0.05</td>
      <td>0.02</td>
      <td>0.91</td>
      <td>0.00</td>
      <td>...</td>
      <td>15.92</td>
      <td>1.00</td>
      <td>0.000</td>
      <td>1.35</td>
      <td>4.84</td>
      <td>0.00</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7994</th>
      <td>0.01</td>
      <td>10.00</td>
      <td>0.01</td>
      <td>2.00</td>
      <td>0.000</td>
      <td>2.00</td>
      <td>0.00</td>
      <td>0.09</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.000</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>7995</th>
      <td>0.04</td>
      <td>6.85</td>
      <td>0.01</td>
      <td>0.70</td>
      <td>0.030</td>
      <td>0.05</td>
      <td>0.01</td>
      <td>0.03</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>...</td>
      <td>15.92</td>
      <td>1.00</td>
      <td>0.000</td>
      <td>1.35</td>
      <td>4.84</td>
      <td>0.00</td>
      <td>0.04</td>
      <td>0.05</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>7996 rows × 22 columns</p>
</div></div></div>
</div>
<p>Selanjutnya menghitung jumlah outlier di dalam dataset water quality atau data yang memiliki label -1, dan menemukan sebanyak 1999 data termasuk data outlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Menghitung jumlah outlier</span>
<span class="n">total_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Outlier&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Jumlah Outlier:&quot;</span><span class="p">,</span> <span class="n">total_outliers</span><span class="p">)</span>

<span class="c1"># Menghitung jumlah outlier</span>
<span class="n">total_no_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Outlier&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total Data Tanpa Outlier:&quot;</span><span class="p">,</span> <span class="n">total_no_outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total Jumlah Outlier: 1999
Total Data Tanpa Outlier: 5997
</pre></div>
</div>
</div>
</div>
<p>Selanjutnya dilakukan penghapusan data terhadap data outlier, kemudian hasil data yang bebas outlier saya simpan sebagai csv dengan nama data_no_outlier.csv.
Pada data yang bersih atau bebas outlier, didapati bahwa kelas 0 sebanyak 5265 sedangkan kelas 1 yakni sebanyak 732 data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_no_outliers</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Outlier&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">df_no_outliers</span> <span class="o">=</span> <span class="n">df_no_outliers</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Outlier&#39;</span><span class="p">])</span>
<span class="n">df_no_outliers</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;data_no_outliers.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_no_outliers.csv&#39;</span><span class="p">)</span>
<span class="c1"># Menghitung jumlah target pada data tanpa outlier</span>
<span class="n">classnooutlier</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah target pada data tanpa outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classnooutlier</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah target pada data tanpa outlier:
0    5236
1     761
Name: is_safe, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="handling-imbalanced-data">
<h2>Handling Imbalanced Data<a class="headerlink" href="#handling-imbalanced-data" title="Permalink to this heading">#</a></h2>
<p>Balancing kelas pada dataset ini menggunakan teknik Random Over-Sampling With imblearn. Random Over-Sampling With imblearn adalah salah satu teknik yang digunakan untuk menangani ketidakseimbangan kelas. Dalam metode ini, jumlah sampel dalam kelas minoritas ditingkatkan dengan menambahkan salinan acak dari sampel yang sudah ada dalam kelas tersebut. Metode Random Over-Sampling memungkinkan untuk mengatasi ketidakseimbangan kelas tanpa menghapus data dari kelas mayoritas, sehingga tidak ada informasi yang hilang dalam prosesnya.</p>
<p>Sebelum dilakukan preprocessing, data dengan kelas 0 sejumlah 7084 dan kelas 1 sebanyak 912. Akan tetapi setelah dilakukan preprocesing data dengan kelas 0 hanya sebanyak 5265 dan kelas 1 hanya 732 data. Meskipun begitu masih perlu dilakukan balancing kelas agar kelas menjadi proporsional satu sama lain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_no_outliers.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="perbandingan-kelas-data-awal">
<h3>Perbandingan kelas data awal<a class="headerlink" href="#perbandingan-kelas-data-awal" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># sebaran class</span>
<span class="n">class_0</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;class 0 (Not Safe) :&#39;</span><span class="p">,</span> <span class="n">class_0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;class 1 (Safe)     :&#39;</span><span class="p">,</span> <span class="n">class_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e458458d9e0e75bf3958f2f2ada65571919db47fd063c244fa9d05027a1317e7.png" src="_images/e458458d9e0e75bf3958f2f2ada65571919db47fd063c244fa9d05027a1317e7.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class 0 (Not Safe) : (5236, 21)
class 1 (Safe)     : (761, 21)
</pre></div>
</div>
</div>
</div>
</section>
<section id="proses-balancing-data">
<h3>Proses Balancing Data<a class="headerlink" href="#proses-balancing-data" title="Permalink to this heading">#</a></h3>
<p>Proses Random Over Sampling adalah sebagai berikut:
<img src="ProsesRandomOverSampling.png"></img></p>
<ul class="simple">
<li><p>Identifikasi Kelas Minoritas dengan menentukan kelas yang memiliki jumlah sampel lebih sedikit dan dianggap sebagai kelas minoritas.</p></li>
<li><p>Hitung selisih antara jumlah sampel di kelas mayoritas dan kelas minoritas.</p></li>
<li><p>Pilih Sampel Acak Dari kelas minoritas, pilih sampel secara acak sebanyak selisih yang dihitung.</p></li>
<li><p>Duplikasi sampel acak yang telah dipilih dan tambahkan ke dataset. Dengan kata lain, kita menambahkan kembali sampel-sampel ini ke kelas minoritas.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Separate features (X) and target variable (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>

<span class="c1"># Print original class distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data :&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data Kelas Awal:&#39;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="c1"># Initialize RandomOverSampler</span>
<span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Apply Random Over-Sampling to balance the classes</span>
<span class="n">X_ros</span><span class="p">,</span> <span class="n">y_ros</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Print resampled class distribution</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sebaran Data Kelas Setelah Balancing:&#39;</span><span class="p">,</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_ros</span><span class="p">))</span>

<span class="c1"># Menampilkan jumlah data setelah balancing sampling</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Jumlah keseluruhan data setelah balancing sampling :&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Features (X_ros) shape:&#39;</span><span class="p">,</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Target (y_ros) shape:&#39;</span><span class="p">,</span> <span class="n">y_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1">#visualisasi perbandingan data kelas</span>
<span class="c1"># Plot original class distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original Class&#39;</span><span class="p">)</span>

<span class="c1"># Plot resampled class distribution after Random Over-Sampling</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;is_safe&#39;</span><span class="p">:</span> <span class="n">y_ros</span><span class="p">}),</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random Over-Sampling With imblearn&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sebaran Data :
Sebaran Data Kelas Awal: Counter({0: 5236, 1: 761})
Sebaran Data Kelas Setelah Balancing: Counter({1: 5236, 0: 5236})

Jumlah keseluruhan data setelah balancing sampling :
Features (X_ros) shape: (10472, 20)
Target (y_ros) shape: (10472,)
</pre></div>
</div>
<img alt="_images/d13406e11402e3f889383b677af59be4fb04cc4bd7a8dce15a435d32a7b0364d.png" src="_images/d13406e11402e3f889383b677af59be4fb04cc4bd7a8dce15a435d32a7b0364d.png" />
</div>
</div>
<p>Dan didapat data setelah dilakukan over sampling kedua kelas yakni 0 dan 1 menjadi sama sama sebanyak 5265 data. sehingga jumlah data keseluruhan menjadi 10530 data. Hasil data yang telah dilakukan balancing ini kemudian disimpan ke dalam file dengan nama data_balancing.csv</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mengonversi array NumPy ke DataFrame pandas</span>
<span class="n">df_X_ros</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_ros</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">df_y_ros</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_ros</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>
<span class="c1"># Menggabungkan DataFrame X_ros dan y_ros</span>
<span class="n">df_resampled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_X_ros</span><span class="p">,</span> <span class="n">df_y_ros</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Menyimpan DataFrame ke dalam file Excel</span>
<span class="n">df_resampled</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">df_resampled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10467</th>
      <td>1.55</td>
      <td>11.30</td>
      <td>0.02</td>
      <td>3.14</td>
      <td>0.007</td>
      <td>7.52</td>
      <td>0.03</td>
      <td>0.10</td>
      <td>1.38</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.033</td>
      <td>7.43</td>
      <td>1.55</td>
      <td>0.007</td>
      <td>19.77</td>
      <td>2.42</td>
      <td>0.09</td>
      <td>0.26</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10468</th>
      <td>0.05</td>
      <td>29.28</td>
      <td>0.06</td>
      <td>0.40</td>
      <td>0.030</td>
      <td>0.07</td>
      <td>0.02</td>
      <td>1.05</td>
      <td>0.81</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.066</td>
      <td>4.62</td>
      <td>0.90</td>
      <td>0.000</td>
      <td>2.08</td>
      <td>1.80</td>
      <td>0.07</td>
      <td>0.09</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10469</th>
      <td>0.39</td>
      <td>28.28</td>
      <td>0.44</td>
      <td>1.74</td>
      <td>0.120</td>
      <td>5.14</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>1.29</td>
      <td>0.43</td>
      <td>...</td>
      <td>0.108</td>
      <td>9.90</td>
      <td>1.86</td>
      <td>0.004</td>
      <td>29.06</td>
      <td>2.12</td>
      <td>0.07</td>
      <td>0.07</td>
      <td>0.01</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10470</th>
      <td>3.12</td>
      <td>18.12</td>
      <td>0.03</td>
      <td>3.98</td>
      <td>0.006</td>
      <td>1.87</td>
      <td>0.07</td>
      <td>0.66</td>
      <td>0.04</td>
      <td>0.32</td>
      <td>...</td>
      <td>0.028</td>
      <td>8.02</td>
      <td>1.07</td>
      <td>0.002</td>
      <td>40.27</td>
      <td>1.16</td>
      <td>0.00</td>
      <td>0.35</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10471</th>
      <td>1.14</td>
      <td>17.45</td>
      <td>0.35</td>
      <td>1.32</td>
      <td>0.040</td>
      <td>1.45</td>
      <td>0.38</td>
      <td>0.41</td>
      <td>0.72</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.020</td>
      <td>1.27</td>
      <td>1.55</td>
      <td>0.010</td>
      <td>45.06</td>
      <td>2.97</td>
      <td>0.06</td>
      <td>0.10</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10472 rows × 21 columns</p>
</div></div></div>
</div>
</section>
</section>
<section id="feature-scaling">
<h2>Feature Scaling<a class="headerlink" href="#feature-scaling" title="Permalink to this heading">#</a></h2>
<p>Feature scaling (skala fitur) adalah teknik khusus di dalam data transformation yang mengubah nilai-nilai variabel ke dalam rentang tertentu, sehingga memastikan bahwa seluruh fitur memiliki skala yang serupa. Feature scaling sendiri bisa disebut dengan normalisasi data. dalam feature scaling kali ini saya akan memilih menggunakan metode robust scaler.</p>
<p>Metode Normalisasi Robust Scaler adalah salah satu teknik normalisasi data yang tahan terhadap outlier.<br />
Robust Scaler mengubah setiap nilai dalam suatu fitur dengan menggunakan rumus berikut: \begin{equation}
X_{\text{scaled}} = \frac}
\end{equation}
Dimana :</p>
<ul class="simple">
<li><p>Xscaled : adalah nilai yang telah diubah skala,</p></li>
<li><p>X : adalah nilai asli,</p></li>
<li><p>Q1 : adalah kuartil pertama (25th percentile),</p></li>
<li><p>Q3 :  adalah kuartil ketiga (75th percentile),</p></li>
<li><p>Median : Nilai Tengah.</p></li>
</ul>
<p>Berikut adalah proses normalisasi menggunakan Robust Scaler dan contoh kasusnya:</p>
<p>Proses Normalisasi menggunakan Robust Scaler:</p>
<ol class="arabic simple">
<li><p>Hitung Median dan Kuartil:</p>
<ul class="simple">
<li><p>Median (Q2): Nilai tengah dari set data.</p></li>
<li><p>Kuartil 1 (Q1): Nilai tengah antara nilai terkecil dan median.</p></li>
<li><p>Kuartil 3 (Q3): Nilai tengah antara median dan nilai terbesar.</p></li>
</ul>
</li>
<li><p>Hitung Rentang Interkuartil (IQR):</p>
<ul class="simple">
<li><p>IQR = Q3 - Q1.</p></li>
</ul>
</li>
<li><p>Hitung Skala Robust:</p>
<ul class="simple">
<li><p>Skala Robust = (X - Median) / IQR.
Contoh Kasus:
Misalkan kita memiliki dataset sebagai berikut:</p></li>
</ul>
</li>
</ol>
<p>[10, 15, 20, 25, 30, 100]</p>
<p>Langkah-langkah Normalisasi menggunakan Robust Scaler:</p>
<ol class="arabic simple">
<li><p>Hitung Median (Q2): Median = 22.5</p></li>
<li><p>Hitung Kuartil 1 (Q1): Q1 = 15</p></li>
<li><p>Hitung Kuartil 3 (Q3): Q3 = 30</p></li>
<li><p>Hitung IQR: IQR = Q3 - Q1 = 15</p></li>
<li><p>Hitung Skala Robust: Skala Robust = (X - Median) / IQR</p>
<ul class="simple">
<li><p>Untuk nilai 10: (10 - 22.5) / 15 = -0.8333</p></li>
<li><p>Untuk nilai 15: (15 - 22.5) / 15 = -0.5</p></li>
<li><p>Untuk nilai 20: (20 - 22.5) / 15 = -0.3333</p></li>
<li><p>Untuk nilai 25: (25 - 22.5) / 15 = 0.1667</p></li>
<li><p>Untuk nilai 30: (30 - 22.5) / 15 = 0.5</p></li>
<li><p>Untuk nilai 100: (100 - 22.5) / 15 = 4.5</p></li>
</ul>
</li>
</ol>
<p>Sehingga, dataset yang telah dinormalisasi menggunakan Robust Scaler adalah:</p>
<p>[-0.8333, -0.5, -0.3333, 0.1667, 0.5, 4.5]</p>
<ul class="simple">
<li><p>Metode Robust Scaler ini memiliki keuntungan:</p>
<ul>
<li><p>Tahan terhadap outlier: Robust Scaler lebih tahan terhadap outlier karena menggunakan informasi dari kuartil, yang kurang dipengaruhi oleh nilai ekstrem.</p></li>
<li><p>Konservatif: Dengan menggunakan median dan IQR, metode ini dapat menghasilkan normalisasi yang lebih konservatif daripada Min-Max Scaling.</p></li>
</ul>
</li>
<li><p>Metode Robust Scaler Cocok Digunakan Jika:</p>
<ul>
<li><p>Data mengandung nilai ekstrem atau outlier.</p></li>
<li><p>Distribusi data tidak terdistribusi normal.</p></li>
<li><p>Skala fitur bervariasi secara signifikan.</p></li>
</ul>
</li>
<li><p>Perbandingan dengan Min-Max Scaling dan Z-Score Scaling:</p>
<ul>
<li><p>Min-Max Scaling: Rentang nilai diubah menjadi 0 hingga 1. Rentang ini dapat sangat dipengaruhi oleh nilai outlier. Jika outlier signifikan, rentang nilai mungkin menjadi terlalu sempit.</p></li>
<li><p>Z-Score Scaling (Standardization): Data diubah sehingga memiliki rata-rata 0 dan deviasi standar 1. Metode ini sensitif terhadap nilai ekstrem dan tidak sebaik Robust Scaler ketika ada outlier.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="c1"># Inisialisasi RobustScaler</span>
<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>

<span class="c1"># Fit dan transformasi data menggunakan RobustScaler</span>
<span class="n">df_scaled</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Membuat DataFrame baru dengan data yang telah diubah skala</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">])</span>
<span class="n">datascled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_normalized</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">datascled</span><span class="p">)</span>
<span class="n">df_normalized</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;data_normalisasi.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Data:&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original Data:
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10467</th>
      <td>1.55</td>
      <td>11.30</td>
      <td>0.02</td>
      <td>3.14</td>
      <td>0.007</td>
      <td>7.52</td>
      <td>0.03</td>
      <td>0.10</td>
      <td>1.38</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.033</td>
      <td>7.43</td>
      <td>1.55</td>
      <td>0.007</td>
      <td>19.77</td>
      <td>2.42</td>
      <td>0.09</td>
      <td>0.26</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10468</th>
      <td>0.05</td>
      <td>29.28</td>
      <td>0.06</td>
      <td>0.40</td>
      <td>0.030</td>
      <td>0.07</td>
      <td>0.02</td>
      <td>1.05</td>
      <td>0.81</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.066</td>
      <td>4.62</td>
      <td>0.90</td>
      <td>0.000</td>
      <td>2.08</td>
      <td>1.80</td>
      <td>0.07</td>
      <td>0.09</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10469</th>
      <td>0.39</td>
      <td>28.28</td>
      <td>0.44</td>
      <td>1.74</td>
      <td>0.120</td>
      <td>5.14</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>1.29</td>
      <td>0.43</td>
      <td>...</td>
      <td>0.108</td>
      <td>9.90</td>
      <td>1.86</td>
      <td>0.004</td>
      <td>29.06</td>
      <td>2.12</td>
      <td>0.07</td>
      <td>0.07</td>
      <td>0.01</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10470</th>
      <td>3.12</td>
      <td>18.12</td>
      <td>0.03</td>
      <td>3.98</td>
      <td>0.006</td>
      <td>1.87</td>
      <td>0.07</td>
      <td>0.66</td>
      <td>0.04</td>
      <td>0.32</td>
      <td>...</td>
      <td>0.028</td>
      <td>8.02</td>
      <td>1.07</td>
      <td>0.002</td>
      <td>40.27</td>
      <td>1.16</td>
      <td>0.00</td>
      <td>0.35</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10471</th>
      <td>1.14</td>
      <td>17.45</td>
      <td>0.35</td>
      <td>1.32</td>
      <td>0.040</td>
      <td>1.45</td>
      <td>0.38</td>
      <td>0.41</td>
      <td>0.72</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.020</td>
      <td>1.27</td>
      <td>1.55</td>
      <td>0.010</td>
      <td>45.06</td>
      <td>2.97</td>
      <td>0.06</td>
      <td>0.10</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10472 rows × 21 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Normalized Data (Robust Scaling):&quot;</span><span class="p">)</span>
<span class="n">df_normalized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normalized Data (Robust Scaling):
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10467</th>
      <td>1.55</td>
      <td>11.30</td>
      <td>0.02</td>
      <td>3.14</td>
      <td>0.007</td>
      <td>7.52</td>
      <td>0.03</td>
      <td>0.10</td>
      <td>1.38</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.033</td>
      <td>7.43</td>
      <td>1.55</td>
      <td>0.007</td>
      <td>19.77</td>
      <td>2.42</td>
      <td>0.09</td>
      <td>0.26</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10468</th>
      <td>0.05</td>
      <td>29.28</td>
      <td>0.06</td>
      <td>0.40</td>
      <td>0.030</td>
      <td>0.07</td>
      <td>0.02</td>
      <td>1.05</td>
      <td>0.81</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.066</td>
      <td>4.62</td>
      <td>0.90</td>
      <td>0.000</td>
      <td>2.08</td>
      <td>1.80</td>
      <td>0.07</td>
      <td>0.09</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10469</th>
      <td>0.39</td>
      <td>28.28</td>
      <td>0.44</td>
      <td>1.74</td>
      <td>0.120</td>
      <td>5.14</td>
      <td>0.05</td>
      <td>0.03</td>
      <td>1.29</td>
      <td>0.43</td>
      <td>...</td>
      <td>0.108</td>
      <td>9.90</td>
      <td>1.86</td>
      <td>0.004</td>
      <td>29.06</td>
      <td>2.12</td>
      <td>0.07</td>
      <td>0.07</td>
      <td>0.01</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10470</th>
      <td>3.12</td>
      <td>18.12</td>
      <td>0.03</td>
      <td>3.98</td>
      <td>0.006</td>
      <td>1.87</td>
      <td>0.07</td>
      <td>0.66</td>
      <td>0.04</td>
      <td>0.32</td>
      <td>...</td>
      <td>0.028</td>
      <td>8.02</td>
      <td>1.07</td>
      <td>0.002</td>
      <td>40.27</td>
      <td>1.16</td>
      <td>0.00</td>
      <td>0.35</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10471</th>
      <td>1.14</td>
      <td>17.45</td>
      <td>0.35</td>
      <td>1.32</td>
      <td>0.040</td>
      <td>1.45</td>
      <td>0.38</td>
      <td>0.41</td>
      <td>0.72</td>
      <td>0.00</td>
      <td>...</td>
      <td>0.020</td>
      <td>1.27</td>
      <td>1.55</td>
      <td>0.010</td>
      <td>45.06</td>
      <td>2.97</td>
      <td>0.06</td>
      <td>0.10</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10472 rows × 21 columns</p>
</div></div></div>
</div>
</section>
<section id="splitting-data">
<h2>Splitting Data<a class="headerlink" href="#splitting-data" title="Permalink to this heading">#</a></h2>
<p>Memisahkan dataset menjadi set pelatihan dan set pengujian untuk evaluasi model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_normalisasi.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="pycaret-seleksi-model">
<h2>Pycaret Seleksi Model<a class="headerlink" href="#pycaret-seleksi-model" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pycaret.regression</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pycaret.classification</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">setup</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;is_safe&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_bb8f5_row8_col1 {
  background-color: lightgreen;
}
</style>
<table id="T_bb8f5">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_bb8f5_level0_col0" class="col_heading level0 col0" >Description</th>
      <th id="T_bb8f5_level0_col1" class="col_heading level0 col1" >Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_bb8f5_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_bb8f5_row0_col0" class="data row0 col0" >Session id</td>
      <td id="T_bb8f5_row0_col1" class="data row0 col1" >6165</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_bb8f5_row1_col0" class="data row1 col0" >Target</td>
      <td id="T_bb8f5_row1_col1" class="data row1 col1" >is_safe</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_bb8f5_row2_col0" class="data row2 col0" >Target type</td>
      <td id="T_bb8f5_row2_col1" class="data row2 col1" >Binary</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_bb8f5_row3_col0" class="data row3 col0" >Original data shape</td>
      <td id="T_bb8f5_row3_col1" class="data row3 col1" >(10472, 21)</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_bb8f5_row4_col0" class="data row4 col0" >Transformed data shape</td>
      <td id="T_bb8f5_row4_col1" class="data row4 col1" >(10472, 21)</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_bb8f5_row5_col0" class="data row5 col0" >Transformed train set shape</td>
      <td id="T_bb8f5_row5_col1" class="data row5 col1" >(7330, 21)</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_bb8f5_row6_col0" class="data row6 col0" >Transformed test set shape</td>
      <td id="T_bb8f5_row6_col1" class="data row6 col1" >(3142, 21)</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_bb8f5_row7_col0" class="data row7 col0" >Numeric features</td>
      <td id="T_bb8f5_row7_col1" class="data row7 col1" >20</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_bb8f5_row8_col0" class="data row8 col0" >Preprocess</td>
      <td id="T_bb8f5_row8_col1" class="data row8 col1" >True</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_bb8f5_row9_col0" class="data row9 col0" >Imputation type</td>
      <td id="T_bb8f5_row9_col1" class="data row9 col1" >simple</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_bb8f5_row10_col0" class="data row10 col0" >Numeric imputation</td>
      <td id="T_bb8f5_row10_col1" class="data row10 col1" >mean</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_bb8f5_row11_col0" class="data row11 col0" >Categorical imputation</td>
      <td id="T_bb8f5_row11_col1" class="data row11 col1" >mode</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_bb8f5_row12_col0" class="data row12 col0" >Fold Generator</td>
      <td id="T_bb8f5_row12_col1" class="data row12 col1" >StratifiedKFold</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_bb8f5_row13_col0" class="data row13 col0" >Fold Number</td>
      <td id="T_bb8f5_row13_col1" class="data row13 col1" >10</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_bb8f5_row14_col0" class="data row14 col0" >CPU Jobs</td>
      <td id="T_bb8f5_row14_col1" class="data row14 col1" >-1</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_bb8f5_row15_col0" class="data row15 col0" >Use GPU</td>
      <td id="T_bb8f5_row15_col1" class="data row15 col1" >False</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_bb8f5_row16_col0" class="data row16 col0" >Log Experiment</td>
      <td id="T_bb8f5_row16_col1" class="data row16 col1" >False</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_bb8f5_row17_col0" class="data row17 col0" >Experiment Name</td>
      <td id="T_bb8f5_row17_col1" class="data row17 col1" >clf-default-name</td>
    </tr>
    <tr>
      <th id="T_bb8f5_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_bb8f5_row18_col0" class="data row18 col0" >USI</td>
      <td id="T_bb8f5_row18_col1" class="data row18 col1" >f125</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">compare_models</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_14404 th {
  text-align: left;
}
#T_14404_row0_col0, #T_14404_row0_col2, #T_14404_row0_col3, #T_14404_row1_col0, #T_14404_row1_col1, #T_14404_row1_col3, #T_14404_row1_col4, #T_14404_row1_col5, #T_14404_row1_col6, #T_14404_row1_col7, #T_14404_row2_col0, #T_14404_row2_col1, #T_14404_row2_col2, #T_14404_row2_col4, #T_14404_row2_col5, #T_14404_row2_col6, #T_14404_row2_col7, #T_14404_row3_col0, #T_14404_row3_col1, #T_14404_row3_col2, #T_14404_row3_col3, #T_14404_row3_col4, #T_14404_row3_col5, #T_14404_row3_col6, #T_14404_row3_col7, #T_14404_row4_col0, #T_14404_row4_col1, #T_14404_row4_col2, #T_14404_row4_col3, #T_14404_row4_col4, #T_14404_row4_col5, #T_14404_row4_col6, #T_14404_row4_col7, #T_14404_row5_col0, #T_14404_row5_col1, #T_14404_row5_col2, #T_14404_row5_col3, #T_14404_row5_col4, #T_14404_row5_col5, #T_14404_row5_col6, #T_14404_row5_col7, #T_14404_row6_col0, #T_14404_row6_col1, #T_14404_row6_col2, #T_14404_row6_col3, #T_14404_row6_col4, #T_14404_row6_col5, #T_14404_row6_col6, #T_14404_row6_col7, #T_14404_row7_col0, #T_14404_row7_col1, #T_14404_row7_col2, #T_14404_row7_col3, #T_14404_row7_col4, #T_14404_row7_col5, #T_14404_row7_col6, #T_14404_row7_col7, #T_14404_row8_col0, #T_14404_row8_col1, #T_14404_row8_col2, #T_14404_row8_col3, #T_14404_row8_col4, #T_14404_row8_col5, #T_14404_row8_col6, #T_14404_row8_col7, #T_14404_row9_col0, #T_14404_row9_col1, #T_14404_row9_col2, #T_14404_row9_col3, #T_14404_row9_col4, #T_14404_row9_col5, #T_14404_row9_col6, #T_14404_row9_col7, #T_14404_row10_col0, #T_14404_row10_col1, #T_14404_row10_col2, #T_14404_row10_col3, #T_14404_row10_col4, #T_14404_row10_col5, #T_14404_row10_col6, #T_14404_row10_col7, #T_14404_row11_col0, #T_14404_row11_col1, #T_14404_row11_col2, #T_14404_row11_col3, #T_14404_row11_col4, #T_14404_row11_col5, #T_14404_row11_col6, #T_14404_row11_col7, #T_14404_row12_col0, #T_14404_row12_col1, #T_14404_row12_col2, #T_14404_row12_col3, #T_14404_row12_col4, #T_14404_row12_col5, #T_14404_row12_col6, #T_14404_row12_col7, #T_14404_row13_col0, #T_14404_row13_col1, #T_14404_row13_col2, #T_14404_row13_col3, #T_14404_row13_col4, #T_14404_row13_col5, #T_14404_row13_col6, #T_14404_row13_col7 {
  text-align: left;
}
#T_14404_row0_col1, #T_14404_row0_col4, #T_14404_row0_col5, #T_14404_row0_col6, #T_14404_row0_col7, #T_14404_row1_col2, #T_14404_row2_col3 {
  text-align: left;
  background-color: yellow;
}
#T_14404_row0_col8, #T_14404_row1_col8, #T_14404_row2_col8, #T_14404_row3_col8, #T_14404_row4_col8, #T_14404_row5_col8, #T_14404_row6_col8, #T_14404_row7_col8, #T_14404_row8_col8, #T_14404_row10_col8, #T_14404_row11_col8, #T_14404_row12_col8, #T_14404_row13_col8 {
  text-align: left;
  background-color: lightgrey;
}
#T_14404_row9_col8 {
  text-align: left;
  background-color: yellow;
  background-color: lightgrey;
}
</style>
<table id="T_14404">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_14404_level0_col0" class="col_heading level0 col0" >Model</th>
      <th id="T_14404_level0_col1" class="col_heading level0 col1" >Accuracy</th>
      <th id="T_14404_level0_col2" class="col_heading level0 col2" >AUC</th>
      <th id="T_14404_level0_col3" class="col_heading level0 col3" >Recall</th>
      <th id="T_14404_level0_col4" class="col_heading level0 col4" >Prec.</th>
      <th id="T_14404_level0_col5" class="col_heading level0 col5" >F1</th>
      <th id="T_14404_level0_col6" class="col_heading level0 col6" >Kappa</th>
      <th id="T_14404_level0_col7" class="col_heading level0 col7" >MCC</th>
      <th id="T_14404_level0_col8" class="col_heading level0 col8" >TT (Sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_14404_level0_row0" class="row_heading level0 row0" >et</th>
      <td id="T_14404_row0_col0" class="data row0 col0" >Extra Trees Classifier</td>
      <td id="T_14404_row0_col1" class="data row0 col1" >0.9854</td>
      <td id="T_14404_row0_col2" class="data row0 col2" >0.9991</td>
      <td id="T_14404_row0_col3" class="data row0 col3" >0.9937</td>
      <td id="T_14404_row0_col4" class="data row0 col4" >0.9775</td>
      <td id="T_14404_row0_col5" class="data row0 col5" >0.9855</td>
      <td id="T_14404_row0_col6" class="data row0 col6" >0.9708</td>
      <td id="T_14404_row0_col7" class="data row0 col7" >0.9710</td>
      <td id="T_14404_row0_col8" class="data row0 col8" >2.1500</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row1" class="row_heading level0 row1" >rf</th>
      <td id="T_14404_row1_col0" class="data row1 col0" >Random Forest Classifier</td>
      <td id="T_14404_row1_col1" class="data row1 col1" >0.9839</td>
      <td id="T_14404_row1_col2" class="data row1 col2" >0.9996</td>
      <td id="T_14404_row1_col3" class="data row1 col3" >0.9967</td>
      <td id="T_14404_row1_col4" class="data row1 col4" >0.9718</td>
      <td id="T_14404_row1_col5" class="data row1 col5" >0.9841</td>
      <td id="T_14404_row1_col6" class="data row1 col6" >0.9678</td>
      <td id="T_14404_row1_col7" class="data row1 col7" >0.9682</td>
      <td id="T_14404_row1_col8" class="data row1 col8" >2.7610</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row2" class="row_heading level0 row2" >lightgbm</th>
      <td id="T_14404_row2_col0" class="data row2 col0" >Light Gradient Boosting Machine</td>
      <td id="T_14404_row2_col1" class="data row2 col1" >0.9835</td>
      <td id="T_14404_row2_col2" class="data row2 col2" >0.9989</td>
      <td id="T_14404_row2_col3" class="data row2 col3" >0.9984</td>
      <td id="T_14404_row2_col4" class="data row2 col4" >0.9696</td>
      <td id="T_14404_row2_col5" class="data row2 col5" >0.9837</td>
      <td id="T_14404_row2_col6" class="data row2 col6" >0.9670</td>
      <td id="T_14404_row2_col7" class="data row2 col7" >0.9674</td>
      <td id="T_14404_row2_col8" class="data row2 col8" >1.7530</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row3" class="row_heading level0 row3" >dt</th>
      <td id="T_14404_row3_col0" class="data row3 col0" >Decision Tree Classifier</td>
      <td id="T_14404_row3_col1" class="data row3 col1" >0.9798</td>
      <td id="T_14404_row3_col2" class="data row3 col2" >0.9798</td>
      <td id="T_14404_row3_col3" class="data row3 col3" >0.9978</td>
      <td id="T_14404_row3_col4" class="data row3 col4" >0.9632</td>
      <td id="T_14404_row3_col5" class="data row3 col5" >0.9802</td>
      <td id="T_14404_row3_col6" class="data row3 col6" >0.9596</td>
      <td id="T_14404_row3_col7" class="data row3 col7" >0.9603</td>
      <td id="T_14404_row3_col8" class="data row3 col8" >0.1410</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row4" class="row_heading level0 row4" >gbc</th>
      <td id="T_14404_row4_col0" class="data row4 col0" >Gradient Boosting Classifier</td>
      <td id="T_14404_row4_col1" class="data row4 col1" >0.9524</td>
      <td id="T_14404_row4_col2" class="data row4 col2" >0.9897</td>
      <td id="T_14404_row4_col3" class="data row4 col3" >0.9744</td>
      <td id="T_14404_row4_col4" class="data row4 col4" >0.9335</td>
      <td id="T_14404_row4_col5" class="data row4 col5" >0.9534</td>
      <td id="T_14404_row4_col6" class="data row4 col6" >0.9048</td>
      <td id="T_14404_row4_col7" class="data row4 col7" >0.9058</td>
      <td id="T_14404_row4_col8" class="data row4 col8" >14.4960</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row5" class="row_heading level0 row5" >ada</th>
      <td id="T_14404_row5_col0" class="data row5 col0" >Ada Boost Classifier</td>
      <td id="T_14404_row5_col1" class="data row5 col1" >0.8774</td>
      <td id="T_14404_row5_col2" class="data row5 col2" >0.9541</td>
      <td id="T_14404_row5_col3" class="data row5 col3" >0.8707</td>
      <td id="T_14404_row5_col4" class="data row5 col4" >0.8825</td>
      <td id="T_14404_row5_col5" class="data row5 col5" >0.8765</td>
      <td id="T_14404_row5_col6" class="data row5 col6" >0.7547</td>
      <td id="T_14404_row5_col7" class="data row5 col7" >0.7549</td>
      <td id="T_14404_row5_col8" class="data row5 col8" >4.4750</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row6" class="row_heading level0 row6" >qda</th>
      <td id="T_14404_row6_col0" class="data row6 col0" >Quadratic Discriminant Analysis</td>
      <td id="T_14404_row6_col1" class="data row6 col1" >0.8308</td>
      <td id="T_14404_row6_col2" class="data row6 col2" >0.9030</td>
      <td id="T_14404_row6_col3" class="data row6 col3" >0.8701</td>
      <td id="T_14404_row6_col4" class="data row6 col4" >0.8068</td>
      <td id="T_14404_row6_col5" class="data row6 col5" >0.8372</td>
      <td id="T_14404_row6_col6" class="data row6 col6" >0.6617</td>
      <td id="T_14404_row6_col7" class="data row6 col7" >0.6638</td>
      <td id="T_14404_row6_col8" class="data row6 col8" >0.1070</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row7" class="row_heading level0 row7" >knn</th>
      <td id="T_14404_row7_col0" class="data row7 col0" >K Neighbors Classifier</td>
      <td id="T_14404_row7_col1" class="data row7 col1" >0.8267</td>
      <td id="T_14404_row7_col2" class="data row7 col2" >0.8966</td>
      <td id="T_14404_row7_col3" class="data row7 col3" >0.9460</td>
      <td id="T_14404_row7_col4" class="data row7 col4" >0.7641</td>
      <td id="T_14404_row7_col5" class="data row7 col5" >0.8453</td>
      <td id="T_14404_row7_col6" class="data row7 col6" >0.6535</td>
      <td id="T_14404_row7_col7" class="data row7 col7" >0.6730</td>
      <td id="T_14404_row7_col8" class="data row7 col8" >0.2130</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row8" class="row_heading level0 row8" >lda</th>
      <td id="T_14404_row8_col0" class="data row8 col0" >Linear Discriminant Analysis</td>
      <td id="T_14404_row8_col1" class="data row8 col1" >0.7917</td>
      <td id="T_14404_row8_col2" class="data row8 col2" >0.8640</td>
      <td id="T_14404_row8_col3" class="data row8 col3" >0.7905</td>
      <td id="T_14404_row8_col4" class="data row8 col4" >0.7928</td>
      <td id="T_14404_row8_col5" class="data row8 col5" >0.7914</td>
      <td id="T_14404_row8_col6" class="data row8 col6" >0.5834</td>
      <td id="T_14404_row8_col7" class="data row8 col7" >0.5837</td>
      <td id="T_14404_row8_col8" class="data row8 col8" >0.1850</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row9" class="row_heading level0 row9" >ridge</th>
      <td id="T_14404_row9_col0" class="data row9 col0" >Ridge Classifier</td>
      <td id="T_14404_row9_col1" class="data row9 col1" >0.7906</td>
      <td id="T_14404_row9_col2" class="data row9 col2" >0.0000</td>
      <td id="T_14404_row9_col3" class="data row9 col3" >0.7812</td>
      <td id="T_14404_row9_col4" class="data row9 col4" >0.7965</td>
      <td id="T_14404_row9_col5" class="data row9 col5" >0.7886</td>
      <td id="T_14404_row9_col6" class="data row9 col6" >0.5812</td>
      <td id="T_14404_row9_col7" class="data row9 col7" >0.5816</td>
      <td id="T_14404_row9_col8" class="data row9 col8" >0.0470</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row10" class="row_heading level0 row10" >nb</th>
      <td id="T_14404_row10_col0" class="data row10 col0" >Naive Bayes</td>
      <td id="T_14404_row10_col1" class="data row10 col1" >0.7831</td>
      <td id="T_14404_row10_col2" class="data row10 col2" >0.8283</td>
      <td id="T_14404_row10_col3" class="data row10 col3" >0.8226</td>
      <td id="T_14404_row10_col4" class="data row10 col4" >0.7624</td>
      <td id="T_14404_row10_col5" class="data row10 col5" >0.7913</td>
      <td id="T_14404_row10_col6" class="data row10 col6" >0.5662</td>
      <td id="T_14404_row10_col7" class="data row10 col7" >0.5681</td>
      <td id="T_14404_row10_col8" class="data row10 col8" >0.0790</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row11" class="row_heading level0 row11" >lr</th>
      <td id="T_14404_row11_col0" class="data row11 col0" >Logistic Regression</td>
      <td id="T_14404_row11_col1" class="data row11 col1" >0.7791</td>
      <td id="T_14404_row11_col2" class="data row11 col2" >0.8607</td>
      <td id="T_14404_row11_col3" class="data row11 col3" >0.7528</td>
      <td id="T_14404_row11_col4" class="data row11 col4" >0.7950</td>
      <td id="T_14404_row11_col5" class="data row11 col5" >0.7731</td>
      <td id="T_14404_row11_col6" class="data row11 col6" >0.5583</td>
      <td id="T_14404_row11_col7" class="data row11 col7" >0.5594</td>
      <td id="T_14404_row11_col8" class="data row11 col8" >2.4650</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row12" class="row_heading level0 row12" >svm</th>
      <td id="T_14404_row12_col0" class="data row12 col0" >SVM - Linear Kernel</td>
      <td id="T_14404_row12_col1" class="data row12 col1" >0.6879</td>
      <td id="T_14404_row12_col2" class="data row12 col2" >0.0000</td>
      <td id="T_14404_row12_col3" class="data row12 col3" >0.5977</td>
      <td id="T_14404_row12_col4" class="data row12 col4" >0.7870</td>
      <td id="T_14404_row12_col5" class="data row12 col5" >0.6204</td>
      <td id="T_14404_row12_col6" class="data row12 col6" >0.3759</td>
      <td id="T_14404_row12_col7" class="data row12 col7" >0.4159</td>
      <td id="T_14404_row12_col8" class="data row12 col8" >0.1510</td>
    </tr>
    <tr>
      <th id="T_14404_level0_row13" class="row_heading level0 row13" >dummy</th>
      <td id="T_14404_row13_col0" class="data row13 col0" >Dummy Classifier</td>
      <td id="T_14404_row13_col1" class="data row13 col1" >0.4993</td>
      <td id="T_14404_row13_col2" class="data row13 col2" >0.5000</td>
      <td id="T_14404_row13_col3" class="data row13 col3" >0.5000</td>
      <td id="T_14404_row13_col4" class="data row13 col4" >0.2497</td>
      <td id="T_14404_row13_col5" class="data row13 col5" >0.3330</td>
      <td id="T_14404_row13_col6" class="data row13 col6" >0.0000</td>
      <td id="T_14404_row13_col7" class="data row13 col7" >0.0000</td>
      <td id="T_14404_row13_col8" class="data row13 col8" >0.0760</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
<section id="light-gradient-boosting-machine">
<h3>Light Gradient Boosting Machine<a class="headerlink" href="#light-gradient-boosting-machine" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lightgbm</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;lightgbm&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_cf9a2_row10_col0, #T_cf9a2_row10_col1, #T_cf9a2_row10_col2, #T_cf9a2_row10_col3, #T_cf9a2_row10_col4, #T_cf9a2_row10_col5, #T_cf9a2_row10_col6 {
  background: yellow;
}
</style>
<table id="T_cf9a2">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_cf9a2_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_cf9a2_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_cf9a2_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_cf9a2_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_cf9a2_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_cf9a2_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_cf9a2_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_cf9a2_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_cf9a2_row0_col0" class="data row0 col0" >0.9850</td>
      <td id="T_cf9a2_row0_col1" class="data row0 col1" >0.9991</td>
      <td id="T_cf9a2_row0_col2" class="data row0 col2" >1.0000</td>
      <td id="T_cf9a2_row0_col3" class="data row0 col3" >0.9709</td>
      <td id="T_cf9a2_row0_col4" class="data row0 col4" >0.9852</td>
      <td id="T_cf9a2_row0_col5" class="data row0 col5" >0.9700</td>
      <td id="T_cf9a2_row0_col6" class="data row0 col6" >0.9704</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_cf9a2_row1_col0" class="data row1 col0" >0.9768</td>
      <td id="T_cf9a2_row1_col1" class="data row1 col1" >0.9978</td>
      <td id="T_cf9a2_row1_col2" class="data row1 col2" >1.0000</td>
      <td id="T_cf9a2_row1_col3" class="data row1 col3" >0.9557</td>
      <td id="T_cf9a2_row1_col4" class="data row1 col4" >0.9774</td>
      <td id="T_cf9a2_row1_col5" class="data row1 col5" >0.9536</td>
      <td id="T_cf9a2_row1_col6" class="data row1 col6" >0.9546</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_cf9a2_row2_col0" class="data row2 col0" >0.9795</td>
      <td id="T_cf9a2_row2_col1" class="data row2 col1" >0.9997</td>
      <td id="T_cf9a2_row2_col2" class="data row2 col2" >1.0000</td>
      <td id="T_cf9a2_row2_col3" class="data row2 col3" >0.9607</td>
      <td id="T_cf9a2_row2_col4" class="data row2 col4" >0.9800</td>
      <td id="T_cf9a2_row2_col5" class="data row2 col5" >0.9591</td>
      <td id="T_cf9a2_row2_col6" class="data row2 col6" >0.9599</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_cf9a2_row3_col0" class="data row3 col0" >0.9823</td>
      <td id="T_cf9a2_row3_col1" class="data row3 col1" >0.9993</td>
      <td id="T_cf9a2_row3_col2" class="data row3 col2" >0.9918</td>
      <td id="T_cf9a2_row3_col3" class="data row3 col3" >0.9733</td>
      <td id="T_cf9a2_row3_col4" class="data row3 col4" >0.9825</td>
      <td id="T_cf9a2_row3_col5" class="data row3 col5" >0.9645</td>
      <td id="T_cf9a2_row3_col6" class="data row3 col6" >0.9647</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_cf9a2_row4_col0" class="data row4 col0" >0.9864</td>
      <td id="T_cf9a2_row4_col1" class="data row4 col1" >0.9989</td>
      <td id="T_cf9a2_row4_col2" class="data row4 col2" >1.0000</td>
      <td id="T_cf9a2_row4_col3" class="data row4 col3" >0.9735</td>
      <td id="T_cf9a2_row4_col4" class="data row4 col4" >0.9866</td>
      <td id="T_cf9a2_row4_col5" class="data row4 col5" >0.9727</td>
      <td id="T_cf9a2_row4_col6" class="data row4 col6" >0.9731</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_cf9a2_row5_col0" class="data row5 col0" >0.9877</td>
      <td id="T_cf9a2_row5_col1" class="data row5 col1" >0.9997</td>
      <td id="T_cf9a2_row5_col2" class="data row5 col2" >0.9973</td>
      <td id="T_cf9a2_row5_col3" class="data row5 col3" >0.9786</td>
      <td id="T_cf9a2_row5_col4" class="data row5 col4" >0.9878</td>
      <td id="T_cf9a2_row5_col5" class="data row5 col5" >0.9754</td>
      <td id="T_cf9a2_row5_col6" class="data row5 col6" >0.9756</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_cf9a2_row6_col0" class="data row6 col0" >0.9836</td>
      <td id="T_cf9a2_row6_col1" class="data row6 col1" >0.9983</td>
      <td id="T_cf9a2_row6_col2" class="data row6 col2" >0.9973</td>
      <td id="T_cf9a2_row6_col3" class="data row6 col3" >0.9707</td>
      <td id="T_cf9a2_row6_col4" class="data row6 col4" >0.9838</td>
      <td id="T_cf9a2_row6_col5" class="data row6 col5" >0.9673</td>
      <td id="T_cf9a2_row6_col6" class="data row6 col6" >0.9676</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_cf9a2_row7_col0" class="data row7 col0" >0.9823</td>
      <td id="T_cf9a2_row7_col1" class="data row7 col1" >0.9982</td>
      <td id="T_cf9a2_row7_col2" class="data row7 col2" >0.9973</td>
      <td id="T_cf9a2_row7_col3" class="data row7 col3" >0.9682</td>
      <td id="T_cf9a2_row7_col4" class="data row7 col4" >0.9825</td>
      <td id="T_cf9a2_row7_col5" class="data row7 col5" >0.9645</td>
      <td id="T_cf9a2_row7_col6" class="data row7 col6" >0.9650</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_cf9a2_row8_col0" class="data row8 col0" >0.9877</td>
      <td id="T_cf9a2_row8_col1" class="data row8 col1" >0.9985</td>
      <td id="T_cf9a2_row8_col2" class="data row8 col2" >1.0000</td>
      <td id="T_cf9a2_row8_col3" class="data row8 col3" >0.9760</td>
      <td id="T_cf9a2_row8_col4" class="data row8 col4" >0.9879</td>
      <td id="T_cf9a2_row8_col5" class="data row8 col5" >0.9754</td>
      <td id="T_cf9a2_row8_col6" class="data row8 col6" >0.9757</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_cf9a2_row9_col0" class="data row9 col0" >0.9836</td>
      <td id="T_cf9a2_row9_col1" class="data row9 col1" >0.9996</td>
      <td id="T_cf9a2_row9_col2" class="data row9 col2" >1.0000</td>
      <td id="T_cf9a2_row9_col3" class="data row9 col3" >0.9683</td>
      <td id="T_cf9a2_row9_col4" class="data row9 col4" >0.9839</td>
      <td id="T_cf9a2_row9_col5" class="data row9 col5" >0.9673</td>
      <td id="T_cf9a2_row9_col6" class="data row9 col6" >0.9678</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_cf9a2_row10_col0" class="data row10 col0" >0.9835</td>
      <td id="T_cf9a2_row10_col1" class="data row10 col1" >0.9989</td>
      <td id="T_cf9a2_row10_col2" class="data row10 col2" >0.9984</td>
      <td id="T_cf9a2_row10_col3" class="data row10 col3" >0.9696</td>
      <td id="T_cf9a2_row10_col4" class="data row10 col4" >0.9837</td>
      <td id="T_cf9a2_row10_col5" class="data row10 col5" >0.9670</td>
      <td id="T_cf9a2_row10_col6" class="data row10 col6" >0.9674</td>
    </tr>
    <tr>
      <th id="T_cf9a2_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_cf9a2_row11_col0" class="data row11 col0" >0.0033</td>
      <td id="T_cf9a2_row11_col1" class="data row11 col1" >0.0006</td>
      <td id="T_cf9a2_row11_col2" class="data row11 col2" >0.0025</td>
      <td id="T_cf9a2_row11_col3" class="data row11 col3" >0.0065</td>
      <td id="T_cf9a2_row11_col4" class="data row11 col4" >0.0032</td>
      <td id="T_cf9a2_row11_col5" class="data row11 col5" >0.0066</td>
      <td id="T_cf9a2_row11_col6" class="data row11 col6" >0.0064</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
</section>
<section id="gradient-boosting-classifier">
<h3>Gradient Boosting Classifier<a class="headerlink" href="#gradient-boosting-classifier" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbc</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;gbc&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_59b05_row10_col0, #T_59b05_row10_col1, #T_59b05_row10_col2, #T_59b05_row10_col3, #T_59b05_row10_col4, #T_59b05_row10_col5, #T_59b05_row10_col6 {
  background: yellow;
}
</style>
<table id="T_59b05">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_59b05_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_59b05_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_59b05_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_59b05_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_59b05_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_59b05_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_59b05_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_59b05_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_59b05_row0_col0" class="data row0 col0" >0.9591</td>
      <td id="T_59b05_row0_col1" class="data row0 col1" >0.9925</td>
      <td id="T_59b05_row0_col2" class="data row0 col2" >0.9700</td>
      <td id="T_59b05_row0_col3" class="data row0 col3" >0.9493</td>
      <td id="T_59b05_row0_col4" class="data row0 col4" >0.9596</td>
      <td id="T_59b05_row0_col5" class="data row0 col5" >0.9181</td>
      <td id="T_59b05_row0_col6" class="data row0 col6" >0.9184</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_59b05_row1_col0" class="data row1 col0" >0.9386</td>
      <td id="T_59b05_row1_col1" class="data row1 col1" >0.9847</td>
      <td id="T_59b05_row1_col2" class="data row1 col2" >0.9564</td>
      <td id="T_59b05_row1_col3" class="data row1 col3" >0.9237</td>
      <td id="T_59b05_row1_col4" class="data row1 col4" >0.9398</td>
      <td id="T_59b05_row1_col5" class="data row1 col5" >0.8772</td>
      <td id="T_59b05_row1_col6" class="data row1 col6" >0.8778</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_59b05_row2_col0" class="data row2 col0" >0.9495</td>
      <td id="T_59b05_row2_col1" class="data row2 col1" >0.9906</td>
      <td id="T_59b05_row2_col2" class="data row2 col2" >0.9782</td>
      <td id="T_59b05_row2_col3" class="data row2 col3" >0.9253</td>
      <td id="T_59b05_row2_col4" class="data row2 col4" >0.9510</td>
      <td id="T_59b05_row2_col5" class="data row2 col5" >0.8990</td>
      <td id="T_59b05_row2_col6" class="data row2 col6" >0.9005</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_59b05_row3_col0" class="data row3 col0" >0.9523</td>
      <td id="T_59b05_row3_col1" class="data row3 col1" >0.9927</td>
      <td id="T_59b05_row3_col2" class="data row3 col2" >0.9646</td>
      <td id="T_59b05_row3_col3" class="data row3 col3" >0.9415</td>
      <td id="T_59b05_row3_col4" class="data row3 col4" >0.9529</td>
      <td id="T_59b05_row3_col5" class="data row3 col5" >0.9045</td>
      <td id="T_59b05_row3_col6" class="data row3 col6" >0.9048</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_59b05_row4_col0" class="data row4 col0" >0.9482</td>
      <td id="T_59b05_row4_col1" class="data row4 col1" >0.9851</td>
      <td id="T_59b05_row4_col2" class="data row4 col2" >0.9728</td>
      <td id="T_59b05_row4_col3" class="data row4 col3" >0.9273</td>
      <td id="T_59b05_row4_col4" class="data row4 col4" >0.9495</td>
      <td id="T_59b05_row4_col5" class="data row4 col5" >0.8963</td>
      <td id="T_59b05_row4_col6" class="data row4 col6" >0.8974</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_59b05_row5_col0" class="data row5 col0" >0.9563</td>
      <td id="T_59b05_row5_col1" class="data row5 col1" >0.9932</td>
      <td id="T_59b05_row5_col2" class="data row5 col2" >0.9699</td>
      <td id="T_59b05_row5_col3" class="data row5 col3" >0.9441</td>
      <td id="T_59b05_row5_col4" class="data row5 col4" >0.9569</td>
      <td id="T_59b05_row5_col5" class="data row5 col5" >0.9127</td>
      <td id="T_59b05_row5_col6" class="data row5 col6" >0.9130</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_59b05_row6_col0" class="data row6 col0" >0.9577</td>
      <td id="T_59b05_row6_col1" class="data row6 col1" >0.9879</td>
      <td id="T_59b05_row6_col2" class="data row6 col2" >0.9863</td>
      <td id="T_59b05_row6_col3" class="data row6 col3" >0.9328</td>
      <td id="T_59b05_row6_col4" class="data row6 col4" >0.9588</td>
      <td id="T_59b05_row6_col5" class="data row6 col5" >0.9154</td>
      <td id="T_59b05_row6_col6" class="data row6 col6" >0.9169</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_59b05_row7_col0" class="data row7 col0" >0.9563</td>
      <td id="T_59b05_row7_col1" class="data row7 col1" >0.9903</td>
      <td id="T_59b05_row7_col2" class="data row7 col2" >0.9809</td>
      <td id="T_59b05_row7_col3" class="data row7 col3" >0.9349</td>
      <td id="T_59b05_row7_col4" class="data row7 col4" >0.9573</td>
      <td id="T_59b05_row7_col5" class="data row7 col5" >0.9127</td>
      <td id="T_59b05_row7_col6" class="data row7 col6" >0.9138</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_59b05_row8_col0" class="data row8 col0" >0.9536</td>
      <td id="T_59b05_row8_col1" class="data row8 col1" >0.9917</td>
      <td id="T_59b05_row8_col2" class="data row8 col2" >0.9727</td>
      <td id="T_59b05_row8_col3" class="data row8 col3" >0.9368</td>
      <td id="T_59b05_row8_col4" class="data row8 col4" >0.9544</td>
      <td id="T_59b05_row8_col5" class="data row8 col5" >0.9072</td>
      <td id="T_59b05_row8_col6" class="data row8 col6" >0.9079</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_59b05_row9_col0" class="data row9 col0" >0.9523</td>
      <td id="T_59b05_row9_col1" class="data row9 col1" >0.9887</td>
      <td id="T_59b05_row9_col2" class="data row9 col2" >0.9918</td>
      <td id="T_59b05_row9_col3" class="data row9 col3" >0.9190</td>
      <td id="T_59b05_row9_col4" class="data row9 col4" >0.9540</td>
      <td id="T_59b05_row9_col5" class="data row9 col5" >0.9045</td>
      <td id="T_59b05_row9_col6" class="data row9 col6" >0.9074</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_59b05_row10_col0" class="data row10 col0" >0.9524</td>
      <td id="T_59b05_row10_col1" class="data row10 col1" >0.9897</td>
      <td id="T_59b05_row10_col2" class="data row10 col2" >0.9744</td>
      <td id="T_59b05_row10_col3" class="data row10 col3" >0.9335</td>
      <td id="T_59b05_row10_col4" class="data row10 col4" >0.9534</td>
      <td id="T_59b05_row10_col5" class="data row10 col5" >0.9048</td>
      <td id="T_59b05_row10_col6" class="data row10 col6" >0.9058</td>
    </tr>
    <tr>
      <th id="T_59b05_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_59b05_row11_col0" class="data row11 col0" >0.0057</td>
      <td id="T_59b05_row11_col1" class="data row11 col1" >0.0029</td>
      <td id="T_59b05_row11_col2" class="data row11 col2" >0.0098</td>
      <td id="T_59b05_row11_col3" class="data row11 col3" >0.0092</td>
      <td id="T_59b05_row11_col4" class="data row11 col4" >0.0055</td>
      <td id="T_59b05_row11_col5" class="data row11 col5" >0.0113</td>
      <td id="T_59b05_row11_col6" class="data row11 col6" >0.0114</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
</section>
<section id="random-forest">
<h3>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rf</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_3804f_row10_col0, #T_3804f_row10_col1, #T_3804f_row10_col2, #T_3804f_row10_col3, #T_3804f_row10_col4, #T_3804f_row10_col5, #T_3804f_row10_col6 {
  background: yellow;
}
</style>
<table id="T_3804f">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_3804f_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_3804f_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_3804f_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_3804f_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_3804f_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_3804f_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_3804f_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_3804f_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_3804f_row0_col0" class="data row0 col0" >0.9864</td>
      <td id="T_3804f_row0_col1" class="data row0 col1" >0.9999</td>
      <td id="T_3804f_row0_col2" class="data row0 col2" >0.9973</td>
      <td id="T_3804f_row0_col3" class="data row0 col3" >0.9760</td>
      <td id="T_3804f_row0_col4" class="data row0 col4" >0.9865</td>
      <td id="T_3804f_row0_col5" class="data row0 col5" >0.9727</td>
      <td id="T_3804f_row0_col6" class="data row0 col6" >0.9729</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_3804f_row1_col0" class="data row1 col0" >0.9795</td>
      <td id="T_3804f_row1_col1" class="data row1 col1" >0.9997</td>
      <td id="T_3804f_row1_col2" class="data row1 col2" >1.0000</td>
      <td id="T_3804f_row1_col3" class="data row1 col3" >0.9607</td>
      <td id="T_3804f_row1_col4" class="data row1 col4" >0.9800</td>
      <td id="T_3804f_row1_col5" class="data row1 col5" >0.9591</td>
      <td id="T_3804f_row1_col6" class="data row1 col6" >0.9599</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_3804f_row2_col0" class="data row2 col0" >0.9850</td>
      <td id="T_3804f_row2_col1" class="data row2 col1" >0.9997</td>
      <td id="T_3804f_row2_col2" class="data row2 col2" >0.9973</td>
      <td id="T_3804f_row2_col3" class="data row2 col3" >0.9734</td>
      <td id="T_3804f_row2_col4" class="data row2 col4" >0.9852</td>
      <td id="T_3804f_row2_col5" class="data row2 col5" >0.9700</td>
      <td id="T_3804f_row2_col6" class="data row2 col6" >0.9703</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_3804f_row3_col0" class="data row3 col0" >0.9850</td>
      <td id="T_3804f_row3_col1" class="data row3 col1" >0.9991</td>
      <td id="T_3804f_row3_col2" class="data row3 col2" >0.9891</td>
      <td id="T_3804f_row3_col3" class="data row3 col3" >0.9811</td>
      <td id="T_3804f_row3_col4" class="data row3 col4" >0.9851</td>
      <td id="T_3804f_row3_col5" class="data row3 col5" >0.9700</td>
      <td id="T_3804f_row3_col6" class="data row3 col6" >0.9700</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_3804f_row4_col0" class="data row4 col0" >0.9850</td>
      <td id="T_3804f_row4_col1" class="data row4 col1" >0.9998</td>
      <td id="T_3804f_row4_col2" class="data row4 col2" >1.0000</td>
      <td id="T_3804f_row4_col3" class="data row4 col3" >0.9709</td>
      <td id="T_3804f_row4_col4" class="data row4 col4" >0.9852</td>
      <td id="T_3804f_row4_col5" class="data row4 col5" >0.9700</td>
      <td id="T_3804f_row4_col6" class="data row4 col6" >0.9704</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_3804f_row5_col0" class="data row5 col0" >0.9891</td>
      <td id="T_3804f_row5_col1" class="data row5 col1" >0.9999</td>
      <td id="T_3804f_row5_col2" class="data row5 col2" >1.0000</td>
      <td id="T_3804f_row5_col3" class="data row5 col3" >0.9786</td>
      <td id="T_3804f_row5_col4" class="data row5 col4" >0.9892</td>
      <td id="T_3804f_row5_col5" class="data row5 col5" >0.9782</td>
      <td id="T_3804f_row5_col6" class="data row5 col6" >0.9784</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_3804f_row6_col0" class="data row6 col0" >0.9795</td>
      <td id="T_3804f_row6_col1" class="data row6 col1" >0.9988</td>
      <td id="T_3804f_row6_col2" class="data row6 col2" >0.9918</td>
      <td id="T_3804f_row6_col3" class="data row6 col3" >0.9680</td>
      <td id="T_3804f_row6_col4" class="data row6 col4" >0.9798</td>
      <td id="T_3804f_row6_col5" class="data row6 col5" >0.9591</td>
      <td id="T_3804f_row6_col6" class="data row6 col6" >0.9594</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_3804f_row7_col0" class="data row7 col0" >0.9795</td>
      <td id="T_3804f_row7_col1" class="data row7 col1" >0.9995</td>
      <td id="T_3804f_row7_col2" class="data row7 col2" >0.9918</td>
      <td id="T_3804f_row7_col3" class="data row7 col3" >0.9680</td>
      <td id="T_3804f_row7_col4" class="data row7 col4" >0.9798</td>
      <td id="T_3804f_row7_col5" class="data row7 col5" >0.9591</td>
      <td id="T_3804f_row7_col6" class="data row7 col6" >0.9594</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_3804f_row8_col0" class="data row8 col0" >0.9877</td>
      <td id="T_3804f_row8_col1" class="data row8 col1" >0.9999</td>
      <td id="T_3804f_row8_col2" class="data row8 col2" >1.0000</td>
      <td id="T_3804f_row8_col3" class="data row8 col3" >0.9760</td>
      <td id="T_3804f_row8_col4" class="data row8 col4" >0.9879</td>
      <td id="T_3804f_row8_col5" class="data row8 col5" >0.9754</td>
      <td id="T_3804f_row8_col6" class="data row8 col6" >0.9757</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_3804f_row9_col0" class="data row9 col0" >0.9823</td>
      <td id="T_3804f_row9_col1" class="data row9 col1" >0.9999</td>
      <td id="T_3804f_row9_col2" class="data row9 col2" >1.0000</td>
      <td id="T_3804f_row9_col3" class="data row9 col3" >0.9657</td>
      <td id="T_3804f_row9_col4" class="data row9 col4" >0.9826</td>
      <td id="T_3804f_row9_col5" class="data row9 col5" >0.9645</td>
      <td id="T_3804f_row9_col6" class="data row9 col6" >0.9651</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_3804f_row10_col0" class="data row10 col0" >0.9839</td>
      <td id="T_3804f_row10_col1" class="data row10 col1" >0.9996</td>
      <td id="T_3804f_row10_col2" class="data row10 col2" >0.9967</td>
      <td id="T_3804f_row10_col3" class="data row10 col3" >0.9718</td>
      <td id="T_3804f_row10_col4" class="data row10 col4" >0.9841</td>
      <td id="T_3804f_row10_col5" class="data row10 col5" >0.9678</td>
      <td id="T_3804f_row10_col6" class="data row10 col6" >0.9682</td>
    </tr>
    <tr>
      <th id="T_3804f_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_3804f_row11_col0" class="data row11 col0" >0.0033</td>
      <td id="T_3804f_row11_col1" class="data row11 col1" >0.0004</td>
      <td id="T_3804f_row11_col2" class="data row11 col2" >0.0040</td>
      <td id="T_3804f_row11_col3" class="data row11 col3" >0.0060</td>
      <td id="T_3804f_row11_col4" class="data row11 col4" >0.0033</td>
      <td id="T_3804f_row11_col5" class="data row11 col5" >0.0067</td>
      <td id="T_3804f_row11_col6" class="data row11 col6" >0.0066</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
</section>
<section id="decision-tree-clasifier">
<h3>Decision Tree Clasifier<a class="headerlink" href="#decision-tree-clasifier" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dt</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;dt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_02c55_row10_col0, #T_02c55_row10_col1, #T_02c55_row10_col2, #T_02c55_row10_col3, #T_02c55_row10_col4, #T_02c55_row10_col5, #T_02c55_row10_col6 {
  background: yellow;
}
</style>
<table id="T_02c55">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_02c55_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_02c55_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_02c55_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_02c55_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_02c55_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_02c55_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_02c55_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_02c55_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_02c55_row0_col0" class="data row0 col0" >0.9823</td>
      <td id="T_02c55_row0_col1" class="data row0 col1" >0.9822</td>
      <td id="T_02c55_row0_col2" class="data row0 col2" >0.9973</td>
      <td id="T_02c55_row0_col3" class="data row0 col3" >0.9683</td>
      <td id="T_02c55_row0_col4" class="data row0 col4" >0.9826</td>
      <td id="T_02c55_row0_col5" class="data row0 col5" >0.9645</td>
      <td id="T_02c55_row0_col6" class="data row0 col6" >0.9650</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_02c55_row1_col0" class="data row1 col0" >0.9782</td>
      <td id="T_02c55_row1_col1" class="data row1 col1" >0.9781</td>
      <td id="T_02c55_row1_col2" class="data row1 col2" >0.9973</td>
      <td id="T_02c55_row1_col3" class="data row1 col3" >0.9606</td>
      <td id="T_02c55_row1_col4" class="data row1 col4" >0.9786</td>
      <td id="T_02c55_row1_col5" class="data row1 col5" >0.9563</td>
      <td id="T_02c55_row1_col6" class="data row1 col6" >0.9570</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_02c55_row2_col0" class="data row2 col0" >0.9782</td>
      <td id="T_02c55_row2_col1" class="data row2 col1" >0.9781</td>
      <td id="T_02c55_row2_col2" class="data row2 col2" >0.9973</td>
      <td id="T_02c55_row2_col3" class="data row2 col3" >0.9606</td>
      <td id="T_02c55_row2_col4" class="data row2 col4" >0.9786</td>
      <td id="T_02c55_row2_col5" class="data row2 col5" >0.9563</td>
      <td id="T_02c55_row2_col6" class="data row2 col6" >0.9570</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_02c55_row3_col0" class="data row3 col0" >0.9768</td>
      <td id="T_02c55_row3_col1" class="data row3 col1" >0.9768</td>
      <td id="T_02c55_row3_col2" class="data row3 col2" >0.9973</td>
      <td id="T_02c55_row3_col3" class="data row3 col3" >0.9581</td>
      <td id="T_02c55_row3_col4" class="data row3 col4" >0.9773</td>
      <td id="T_02c55_row3_col5" class="data row3 col5" >0.9536</td>
      <td id="T_02c55_row3_col6" class="data row3 col6" >0.9544</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_02c55_row4_col0" class="data row4 col0" >0.9809</td>
      <td id="T_02c55_row4_col1" class="data row4 col1" >0.9809</td>
      <td id="T_02c55_row4_col2" class="data row4 col2" >1.0000</td>
      <td id="T_02c55_row4_col3" class="data row4 col3" >0.9633</td>
      <td id="T_02c55_row4_col4" class="data row4 col4" >0.9813</td>
      <td id="T_02c55_row4_col5" class="data row4 col5" >0.9618</td>
      <td id="T_02c55_row4_col6" class="data row4 col6" >0.9625</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_02c55_row5_col0" class="data row5 col0" >0.9850</td>
      <td id="T_02c55_row5_col1" class="data row5 col1" >0.9850</td>
      <td id="T_02c55_row5_col2" class="data row5 col2" >0.9945</td>
      <td id="T_02c55_row5_col3" class="data row5 col3" >0.9759</td>
      <td id="T_02c55_row5_col4" class="data row5 col4" >0.9851</td>
      <td id="T_02c55_row5_col5" class="data row5 col5" >0.9700</td>
      <td id="T_02c55_row5_col6" class="data row5 col6" >0.9702</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_02c55_row6_col0" class="data row6 col0" >0.9768</td>
      <td id="T_02c55_row6_col1" class="data row6 col1" >0.9768</td>
      <td id="T_02c55_row6_col2" class="data row6 col2" >0.9973</td>
      <td id="T_02c55_row6_col3" class="data row6 col3" >0.9580</td>
      <td id="T_02c55_row6_col4" class="data row6 col4" >0.9772</td>
      <td id="T_02c55_row6_col5" class="data row6 col5" >0.9536</td>
      <td id="T_02c55_row6_col6" class="data row6 col6" >0.9544</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_02c55_row7_col0" class="data row7 col0" >0.9823</td>
      <td id="T_02c55_row7_col1" class="data row7 col1" >0.9823</td>
      <td id="T_02c55_row7_col2" class="data row7 col2" >0.9973</td>
      <td id="T_02c55_row7_col3" class="data row7 col3" >0.9682</td>
      <td id="T_02c55_row7_col4" class="data row7 col4" >0.9825</td>
      <td id="T_02c55_row7_col5" class="data row7 col5" >0.9645</td>
      <td id="T_02c55_row7_col6" class="data row7 col6" >0.9650</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_02c55_row8_col0" class="data row8 col0" >0.9768</td>
      <td id="T_02c55_row8_col1" class="data row8 col1" >0.9768</td>
      <td id="T_02c55_row8_col2" class="data row8 col2" >1.0000</td>
      <td id="T_02c55_row8_col3" class="data row8 col3" >0.9556</td>
      <td id="T_02c55_row8_col4" class="data row8 col4" >0.9773</td>
      <td id="T_02c55_row8_col5" class="data row8 col5" >0.9536</td>
      <td id="T_02c55_row8_col6" class="data row8 col6" >0.9546</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_02c55_row9_col0" class="data row9 col0" >0.9809</td>
      <td id="T_02c55_row9_col1" class="data row9 col1" >0.9809</td>
      <td id="T_02c55_row9_col2" class="data row9 col2" >1.0000</td>
      <td id="T_02c55_row9_col3" class="data row9 col3" >0.9632</td>
      <td id="T_02c55_row9_col4" class="data row9 col4" >0.9812</td>
      <td id="T_02c55_row9_col5" class="data row9 col5" >0.9618</td>
      <td id="T_02c55_row9_col6" class="data row9 col6" >0.9625</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_02c55_row10_col0" class="data row10 col0" >0.9798</td>
      <td id="T_02c55_row10_col1" class="data row10 col1" >0.9798</td>
      <td id="T_02c55_row10_col2" class="data row10 col2" >0.9978</td>
      <td id="T_02c55_row10_col3" class="data row10 col3" >0.9632</td>
      <td id="T_02c55_row10_col4" class="data row10 col4" >0.9802</td>
      <td id="T_02c55_row10_col5" class="data row10 col5" >0.9596</td>
      <td id="T_02c55_row10_col6" class="data row10 col6" >0.9603</td>
    </tr>
    <tr>
      <th id="T_02c55_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_02c55_row11_col0" class="data row11 col0" >0.0027</td>
      <td id="T_02c55_row11_col1" class="data row11 col1" >0.0027</td>
      <td id="T_02c55_row11_col2" class="data row11 col2" >0.0016</td>
      <td id="T_02c55_row11_col3" class="data row11 col3" >0.0058</td>
      <td id="T_02c55_row11_col4" class="data row11 col4" >0.0026</td>
      <td id="T_02c55_row11_col5" class="data row11 col5" >0.0054</td>
      <td id="T_02c55_row11_col6" class="data row11 col6" >0.0052</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
</section>
<section id="ada-boost-classifier">
<h3>Ada Boost Classifier<a class="headerlink" href="#ada-boost-classifier" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ada</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="s1">&#39;ada&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"></div><div class="output text_html"><style type="text/css">
#T_b4d77_row10_col0, #T_b4d77_row10_col1, #T_b4d77_row10_col2, #T_b4d77_row10_col3, #T_b4d77_row10_col4, #T_b4d77_row10_col5, #T_b4d77_row10_col6 {
  background: yellow;
}
</style>
<table id="T_b4d77">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_b4d77_level0_col0" class="col_heading level0 col0" >Accuracy</th>
      <th id="T_b4d77_level0_col1" class="col_heading level0 col1" >AUC</th>
      <th id="T_b4d77_level0_col2" class="col_heading level0 col2" >Recall</th>
      <th id="T_b4d77_level0_col3" class="col_heading level0 col3" >Prec.</th>
      <th id="T_b4d77_level0_col4" class="col_heading level0 col4" >F1</th>
      <th id="T_b4d77_level0_col5" class="col_heading level0 col5" >Kappa</th>
      <th id="T_b4d77_level0_col6" class="col_heading level0 col6" >MCC</th>
    </tr>
    <tr>
      <th class="index_name level0" >Fold</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
      <th class="blank col3" >&nbsp;</th>
      <th class="blank col4" >&nbsp;</th>
      <th class="blank col5" >&nbsp;</th>
      <th class="blank col6" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_b4d77_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_b4d77_row0_col0" class="data row0 col0" >0.8936</td>
      <td id="T_b4d77_row0_col1" class="data row0 col1" >0.9591</td>
      <td id="T_b4d77_row0_col2" class="data row0 col2" >0.8937</td>
      <td id="T_b4d77_row0_col3" class="data row0 col3" >0.8937</td>
      <td id="T_b4d77_row0_col4" class="data row0 col4" >0.8937</td>
      <td id="T_b4d77_row0_col5" class="data row0 col5" >0.7872</td>
      <td id="T_b4d77_row0_col6" class="data row0 col6" >0.7872</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_b4d77_row1_col0" class="data row1 col0" >0.8568</td>
      <td id="T_b4d77_row1_col1" class="data row1 col1" >0.9422</td>
      <td id="T_b4d77_row1_col2" class="data row1 col2" >0.8447</td>
      <td id="T_b4d77_row1_col3" class="data row1 col3" >0.8659</td>
      <td id="T_b4d77_row1_col4" class="data row1 col4" >0.8552</td>
      <td id="T_b4d77_row1_col5" class="data row1 col5" >0.7135</td>
      <td id="T_b4d77_row1_col6" class="data row1 col6" >0.7137</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_b4d77_row2_col0" class="data row2 col0" >0.8690</td>
      <td id="T_b4d77_row2_col1" class="data row2 col1" >0.9495</td>
      <td id="T_b4d77_row2_col2" class="data row2 col2" >0.8719</td>
      <td id="T_b4d77_row2_col3" class="data row2 col3" >0.8672</td>
      <td id="T_b4d77_row2_col4" class="data row2 col4" >0.8696</td>
      <td id="T_b4d77_row2_col5" class="data row2 col5" >0.7381</td>
      <td id="T_b4d77_row2_col6" class="data row2 col6" >0.7381</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_b4d77_row3_col0" class="data row3 col0" >0.8677</td>
      <td id="T_b4d77_row3_col1" class="data row3 col1" >0.9522</td>
      <td id="T_b4d77_row3_col2" class="data row3 col2" >0.8665</td>
      <td id="T_b4d77_row3_col3" class="data row3 col3" >0.8689</td>
      <td id="T_b4d77_row3_col4" class="data row3 col4" >0.8677</td>
      <td id="T_b4d77_row3_col5" class="data row3 col5" >0.7353</td>
      <td id="T_b4d77_row3_col6" class="data row3 col6" >0.7353</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_b4d77_row4_col0" class="data row4 col0" >0.8677</td>
      <td id="T_b4d77_row4_col1" class="data row4 col1" >0.9485</td>
      <td id="T_b4d77_row4_col2" class="data row4 col2" >0.8501</td>
      <td id="T_b4d77_row4_col3" class="data row4 col3" >0.8814</td>
      <td id="T_b4d77_row4_col4" class="data row4 col4" >0.8655</td>
      <td id="T_b4d77_row4_col5" class="data row4 col5" >0.7353</td>
      <td id="T_b4d77_row4_col6" class="data row4 col6" >0.7358</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_b4d77_row5_col0" class="data row5 col0" >0.8854</td>
      <td id="T_b4d77_row5_col1" class="data row5 col1" >0.9650</td>
      <td id="T_b4d77_row5_col2" class="data row5 col2" >0.8607</td>
      <td id="T_b4d77_row5_col3" class="data row5 col3" >0.9052</td>
      <td id="T_b4d77_row5_col4" class="data row5 col4" >0.8824</td>
      <td id="T_b4d77_row5_col5" class="data row5 col5" >0.7708</td>
      <td id="T_b4d77_row5_col6" class="data row5 col6" >0.7717</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_b4d77_row6_col0" class="data row6 col0" >0.8745</td>
      <td id="T_b4d77_row6_col1" class="data row6 col1" >0.9486</td>
      <td id="T_b4d77_row6_col2" class="data row6 col2" >0.8661</td>
      <td id="T_b4d77_row6_col3" class="data row6 col3" >0.8806</td>
      <td id="T_b4d77_row6_col4" class="data row6 col4" >0.8733</td>
      <td id="T_b4d77_row6_col5" class="data row6 col5" >0.7490</td>
      <td id="T_b4d77_row6_col6" class="data row6 col6" >0.7491</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_b4d77_row7_col0" class="data row7 col0" >0.8799</td>
      <td id="T_b4d77_row7_col1" class="data row7 col1" >0.9569</td>
      <td id="T_b4d77_row7_col2" class="data row7 col2" >0.8743</td>
      <td id="T_b4d77_row7_col3" class="data row7 col3" >0.8840</td>
      <td id="T_b4d77_row7_col4" class="data row7 col4" >0.8791</td>
      <td id="T_b4d77_row7_col5" class="data row7 col5" >0.7599</td>
      <td id="T_b4d77_row7_col6" class="data row7 col6" >0.7599</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_b4d77_row8_col0" class="data row8 col0" >0.8990</td>
      <td id="T_b4d77_row8_col1" class="data row8 col1" >0.9629</td>
      <td id="T_b4d77_row8_col2" class="data row8 col2" >0.9016</td>
      <td id="T_b4d77_row8_col3" class="data row8 col3" >0.8967</td>
      <td id="T_b4d77_row8_col4" class="data row8 col4" >0.8992</td>
      <td id="T_b4d77_row8_col5" class="data row8 col5" >0.7981</td>
      <td id="T_b4d77_row8_col6" class="data row8 col6" >0.7981</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_b4d77_row9_col0" class="data row9 col0" >0.8799</td>
      <td id="T_b4d77_row9_col1" class="data row9 col1" >0.9565</td>
      <td id="T_b4d77_row9_col2" class="data row9 col2" >0.8770</td>
      <td id="T_b4d77_row9_col3" class="data row9 col3" >0.8819</td>
      <td id="T_b4d77_row9_col4" class="data row9 col4" >0.8795</td>
      <td id="T_b4d77_row9_col5" class="data row9 col5" >0.7599</td>
      <td id="T_b4d77_row9_col6" class="data row9 col6" >0.7599</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row10" class="row_heading level0 row10" >Mean</th>
      <td id="T_b4d77_row10_col0" class="data row10 col0" >0.8774</td>
      <td id="T_b4d77_row10_col1" class="data row10 col1" >0.9541</td>
      <td id="T_b4d77_row10_col2" class="data row10 col2" >0.8707</td>
      <td id="T_b4d77_row10_col3" class="data row10 col3" >0.8825</td>
      <td id="T_b4d77_row10_col4" class="data row10 col4" >0.8765</td>
      <td id="T_b4d77_row10_col5" class="data row10 col5" >0.7547</td>
      <td id="T_b4d77_row10_col6" class="data row10 col6" >0.7549</td>
    </tr>
    <tr>
      <th id="T_b4d77_level0_row11" class="row_heading level0 row11" >Std</th>
      <td id="T_b4d77_row11_col0" class="data row11 col0" >0.0123</td>
      <td id="T_b4d77_row11_col1" class="data row11 col1" >0.0068</td>
      <td id="T_b4d77_row11_col2" class="data row11 col2" >0.0167</td>
      <td id="T_b4d77_row11_col3" class="data row11 col3" >0.0124</td>
      <td id="T_b4d77_row11_col4" class="data row11 col4" >0.0125</td>
      <td id="T_b4d77_row11_col5" class="data row11 col5" >0.0245</td>
      <td id="T_b4d77_row11_col6" class="data row11 col6" >0.0245</td>
    </tr>
  </tbody>
</table>
</div><div class="output text_html"></div></div>
</div>
</section>
</section>
<section id="feature-selection">
<h2>Feature Selection<a class="headerlink" href="#feature-selection" title="Permalink to this heading">#</a></h2>
<p>Feature Selection (pemilihan fitur) adalah proses memilih subset fitur yang paling relevan dan informatif dari suatu dataset untuk digunakan dalam pembangunan model atau analisis data. Tujuan utama dari feature selection adalah untuk meningkatkan kinerja model dengan mengurangi kompleksitas dan meningkatkan interpretabilitas, sambil mempertahankan atau meningkatkan keakuratan prediksi. Pada proses seleksi fitur ini menggunakan fungsi Mutual Information.</p>
<p>Mutual Information (Informasi Timbal Balik) adalah suatu metrik yang digunakan untuk mengukur seberapa banyak pengetahuan tentang suatu variabel dapat memberikan wawasan tentang variabel lainnya. Dalam konteks feature selection atau pemilihan fitur, mutual information digunakan untuk mengukur seberapa informatif suatu fitur terhadap variabel target atau variabel kelas.</p>
<p>Rumus Mutual Information :</p>
<div class="math notranslate nohighlight">
\[I(X;Y) = \sum_{x \in X} \sum_{y \in Y} p(x, y) \log\left(\frac{p(x, y)}{p(x)p(y)}\right)\]</div>
<p>dimana :</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(x,y)\)</span> adalah probabilitas bersama dari <span class="math notranslate nohighlight">\(X\)</span> dan <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(p(x)\)</span> dan <span class="math notranslate nohighlight">\(p(y)\)</span> adalah probabilitas marginal dari <span class="math notranslate nohighlight">\(X\)</span> dan <span class="math notranslate nohighlight">\(Y\)</span> masing - masing.</p></li>
</ul>
<p>Information gain diukur sebagai perbedaan antara entropi set data awal dan entropi set data setelah pemisahan berdasarkan fitur A. Semakin tinggi information gain, semakin baik fitur A dalam memisahkan data.</p>
<p><strong>1) Berikut merupakan langkah-langkah dalam menghitung information gain :</strong></p>
<ul>
<li><p><strong>Hitung entropy awal (sebelum pemisahan):</strong></p>
<p>Hitung entropy dataset sebelum dilakukan pemisahan. Berikut merupakan formulanya :</p>
<div class="math notranslate nohighlight">
\[ H(S) = -\sum_{i=1}^{n} p_i \cdot \log_2(p_i) \]</div>
<p><em>Keterangan :</em></p>
<p><em>H(S) = nilai entropy awal</em>
<em>n = jumlah kelas</em>
<em>Pi = proporsi kelas i dalam dataset</em></p>
</li>
<li><p><strong>Hitung entropy setelah pemisahan:</strong>
Menghitung entropy tiap kelompok yang dihasilkan setelah pemisahan berdasarkan suatu fitur. Berikut merupakan formulanya :</p>
<div class="math notranslate nohighlight">
\[ H(S|A) = \sum_{j=1}^{v} \frac{|S_j|}{|S|} \cdot H(S_j) \]</div>
<p><em>Keterangan :</em>
<em>H(S|A) = entropy dataset setelah pemisahan pada fitur A</em>
<em>v = jumlah nilai dalam fitur A</em>
<em>| Sj | = ukuran subset dari fitur A yang mempunyai nilai j</em>
<em>| S | = ukuran dataset</em>
<em>H(Sj) = entropy subset untuk fitur A</em></p>
</li>
<li><p><strong>Hitung information gain:</strong>
$<span class="math notranslate nohighlight">\( \text{Gain}(S, A) = H(S) - H(S|A) \)</span>$</p>
<p><em>Keterangan :</em>
<em>H(S) = entropy awal dataset S</em>
<em>H(S|A) = entropy dataset setelah pemisahan pada fitur A</em></p>
</li>
</ul>
<p><strong>2) Berikut merupakan contoh perhitungan manual menggunakan data dummy :</strong></p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Outlook</p></th>
<th class="head"><p>Temperature</p></th>
<th class="head"><p>Play Tennis</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Sunny</p></td>
<td><p>Hot</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Sunny</p></td>
<td><p>Hot</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>Overcast</p></td>
<td><p>Hot</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>Rainy</p></td>
<td><p>Mild</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>Rainy</p></td>
<td><p>Cool</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>Rainy</p></td>
<td><p>Cool</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>Overcast</p></td>
<td><p>Cool</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>Sunny</p></td>
<td><p>Mild</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>Sunny</p></td>
<td><p>Cool</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>Rainy</p></td>
<td><p>Mild</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
<ul>
<li><p>Menghitung entropy awal :</p>
<div class="math notranslate nohighlight">
\[ H(S) = -p_{\text{Yes}} \cdot \log_2(p_{\text{Yes}}) - p_{\text{No}} \cdot \log_2(p_{\text{No}}) \]</div>
<div class="math notranslate nohighlight">
\[ H(S) = -[\frac{6}{10} \cdot \log_2\left(\frac{6}{10}\right) + \frac{4}{10} \cdot \log_2\left(\frac{4}{10}\right) ] \]</div>
<div class="math notranslate nohighlight">
\[ H(S) = -\left(\frac{6}{10} \log_2\left(\frac{3}{5}\right) + \frac{4}{10} \log_2\left(\frac{2}{5}\right)\right) \]</div>
<div class="math notranslate nohighlight">
\[ H(S) = -\left(-0.4422 - 0.5288\right) \]</div>
<div class="math notranslate nohighlight">
\[ H(S) = 0.971 \]</div>
</li>
<li><p>Menghitung entropy setelah pemisahan (berdasarkan outlook) :</p>
<p><strong>(a) Subset SUNNY</strong>
$<span class="math notranslate nohighlight">\(  [ H(S_{\text{Sunny}}) = -\left(\frac{3}{5} \cdot \log_2\left(\frac{3}{5}\right) + \frac{2}{5} \cdot \log_2\left(\frac{2}{5}\right)\right) ] \)</span>$</p>
<div class="math notranslate nohighlight">
\[ H(S_{\text{Sunny}}) = -\left(\frac{3}{5} \cdot (-0.737) + \frac{2}{5} \cdot (-1.322)\right) \]</div>
<div class="math notranslate nohighlight">
\[ [ H(S_{\text{Sunny}}) = 0.971 ] \]</div>
<p><strong>(b) Subset OVERCAST</strong>
$<span class="math notranslate nohighlight">\( [ H(S_{\text{Overcast}}) = 0 ] (karena  semua instance positif) \)</span>$</p>
<p><strong>(c) Subset RAINY</strong>
$<span class="math notranslate nohighlight">\( [ H(S_{\text{Rainy}}) = -\left(\frac{2}{5} \cdot \log_2\left(\frac{2}{5}\right) + \frac{3}{5} \cdot \log_2\left(\frac{3}{5}\right)\right) ] \)</span>$</p>
<div class="math notranslate nohighlight">
\[ [ H(S_{\text{Rainy}}) = -\left(\frac{2}{5} \cdot (-0.737) + \frac{3}{5} \cdot (-0.971)\right) ] \]</div>
<div class="math notranslate nohighlight">
\[ [ H(S_{\text{Rainy}}) = 0.971 ] \]</div>
<p><strong>(d) Entropy setelah pemisahan</strong>
$<span class="math notranslate nohighlight">\(  [ H(S|\text{Outlook}) = \frac{5}{10} \cdot H(S_{\text{Sunny}}) + \frac{4}{10} \cdot H(S_{\text{Overcast}}) + \frac{5}{10} \cdot H(S_{\text{Rainy}}) ] \)</span>$</p>
<div class="math notranslate nohighlight">
\[ H(S_{\text{Overcast}}) + \frac{5}{10} \cdot H(S_{\text{Rainy}}) \]</div>
<div class="math notranslate nohighlight">
\[ H(S|\text{Outlook}) = \frac{5}{10} \cdot 0.971 + \frac{4}{10} \cdot 0 + \frac{5}{10} \cdot 0.971 \]</div>
<div class="math notranslate nohighlight">
\[ [ H(S|\text{Outlook}) = 0.971 ] \]</div>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_normalisasi.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="c1"># Menghitung Information Gain untuk setiap fitur</span>
<span class="n">information_gains</span> <span class="o">=</span> <span class="n">mutual_info_classif</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Menyusun hasil ke dalam DataFrame untuk analisis</span>
<span class="n">feature_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s1">&#39;information_gain&#39;</span><span class="p">:</span> <span class="n">information_gains</span><span class="p">})</span>
<span class="n">feature_scores</span> <span class="o">=</span> <span class="n">feature_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;information_gain&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Menampilkan hasil Information Gain untuk setiap fitur</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_scores</span><span class="p">)</span>

<span class="c1"># Plotting bar plot untuk perbandingan Information Gain</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">feature_scores</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span> <span class="n">feature_scores</span><span class="p">[</span><span class="s1">&#39;information_gain&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Information Gain&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Feature&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Features by Information Gain&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        feature  information_gain
15  perchlorate          0.331623
1       ammonia          0.301489
12     nitrates          0.222200
0     aluminium          0.216562
4       cadmium          0.193228
5    chloramine          0.180673
16       radium          0.142545
2       arsenic          0.119687
3        barium          0.092841
13     nitrites          0.087851
6      chromium          0.063050
7        copper          0.038504
11         lead          0.036719
10      viruses          0.035334
8      flouride          0.022959
18       silver          0.019000
9      bacteria          0.018768
19      uranium          0.011103
14      mercury          0.003603
17     selenium          0.000720
</pre></div>
</div>
<img alt="_images/9b66ea95a0c8713e461d9da2fd5463683b1dc93b660fdcbaea8f532f7ef36ad5.png" src="_images/9b66ea95a0c8713e461d9da2fd5463683b1dc93b660fdcbaea8f532f7ef36ad5.png" />
</div>
</div>
<section id="pencarian-fitur-terbaik-light-gradient-boosting-machine">
<h3>Pencarian Fitur Terbaik Light Gradient Boosting Machine<a class="headerlink" href="#pencarian-fitur-terbaik-light-gradient-boosting-machine" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Light Gradient Boosting Machine</span>
    <span class="n">lightgbm_model</span> <span class="o">=</span> <span class="n">lightgbm</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">lightgbm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_lightgbm</span> <span class="o">=</span> <span class="n">lightgbm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Light Gradient Boosting Machine</span>
    <span class="n">accuracy_lightgbm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lightgbm</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_lightgbm</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_lightgbm</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">lightgbm_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

        <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Light Gradient Boosting Machine :&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturLightGradientBoostingMachine.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3034
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2834
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2683
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2582
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2571
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2316
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001375 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2115
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2104
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1860
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1605
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1353
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1098
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 843
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 833
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 782
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 721
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 630
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 524
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 269
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 23
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 20
Best Fitur Light Gradient Boosting Machine : Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fiturLightGradientBoostingMachine.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memuat list fitur yang akan di-drop dari file pickle</span>
<span class="n">LightGradientBoostingMachine_drop</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;fiturLightGradientBoostingMachine.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menghilangkan &#39;is_safe&#39; dari setiap nama fitur</span>
<span class="n">LightGradientBoostingMachine_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">LightGradientBoostingMachine_drop</span><span class="p">]</span>

<span class="c1"># Memilih hanya kolom yang ada di pickle</span>
<span class="n">data_LightGradientBoostingMachine_drop</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">LightGradientBoostingMachine_drop</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]]</span>

<span class="c1"># Menampilkan DataFrame setelah fitur di-drop</span>
<span class="n">data_LightGradientBoostingMachine_drop</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
</section>
<section id="pencarian-fitur-terbaik-gradient-boosting-classifier">
<h3>Pencarian Fitur Terbaik Gradient Boosting Classifier<a class="headerlink" href="#pencarian-fitur-terbaik-gradient-boosting-classifier" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Gradient Boosting</span>
    <span class="n">gb_model</span> <span class="o">=</span> <span class="n">gbc</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">gb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_gb</span> <span class="o">=</span> <span class="n">gb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Gradient Boosting</span>
    <span class="n">accuracy_gb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_gb</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_gb</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_gb</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">gb_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

        <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Gradient Boosting :&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturgradientboosting.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 20
Best Fitur Gradient Boosting : Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fiturgradientboosting.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memuat list fitur yang akan di-drop dari file pickle</span>
<span class="n">GradientBoostingClasifier_drop</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;fiturgradientboosting.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menghilangkan &#39;is_safe&#39; dari setiap nama fitur</span>
<span class="n">GradientBoostingClasifier_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">GradientBoostingClasifier_drop</span><span class="p">]</span>

<span class="c1"># Memilih hanya kolom yang ada di pickle</span>
<span class="n">data_GradientBoostingClasifier_drop</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">GradientBoostingClasifier_drop</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]]</span>

<span class="c1"># Menampilkan DataFrame setelah fitur di-drop</span>
<span class="n">data_GradientBoostingClasifier_drop</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
</section>
<section id="pencarian-fitur-terbaik-random-forest">
<h3>Pencarian Fitur Terbaik Random Forest<a class="headerlink" href="#pencarian-fitur-terbaik-random-forest" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Random Forest</span>
    <span class="n">rf_model</span> <span class="o">=</span> <span class="n">rf</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Random Forest</span>
    <span class="n">accuracy_rf</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_rf</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_rf</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">rf_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

        <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Random Forest:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturrandomforest.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 18
Best Fitur Random Forest: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;nitrates&#39;, &#39;nitrites&#39;,
       &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;, &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
bacteria: 2.422481294450292
viruses: 4.429129304026364
nitrates: 173.48651984813026
nitrites: 0.020259579232659978
mercury: 87.74346761883795
perchlorate: 78.22425346978895
radium: 33.07324163404674
selenium: 94.43379608807072
silver: 92.15581382719945
uranium: 14.847178481026724
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fiturrandomforest.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memuat list fitur yang akan di-drop dari file pickle</span>
<span class="n">RandomForest_drop</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;fiturrandomforest.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menghilangkan &#39;is_safe&#39; dari setiap nama fitur</span>
<span class="n">RandomForest_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">RandomForest_drop</span><span class="p">]</span>

<span class="c1"># Memilih hanya kolom yang ada di pickle</span>
<span class="n">data_RandomForest_drop</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">RandomForest_drop</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]]</span>

<span class="c1"># Menampilkan DataFrame setelah fitur di-drop</span>
<span class="n">data_RandomForest_drop</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>bacteria</th>
      <th>viruses</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.20</td>
      <td>0.000</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.65</td>
      <td>0.650</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.05</td>
      <td>0.003</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>0.71</td>
      <td>0.710</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.13</td>
      <td>0.001</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="id1">
<h3>Decision Tree Clasifier<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Decision Tree</span>
    <span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>  <span class="c1"># Ganti dengan parameter yang sesuai</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Decision Tree</span>
    <span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_dt</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_dt</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">dt_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

        <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Decision Tree:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturdecisiontree.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 20
Best Fitur Decision Tree: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fiturdecisiontree.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Random Forest</span>
    <span class="n">dt_model</span> <span class="o">=</span> <span class="n">dt</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Random Forest</span>
    <span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_dt</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_dt</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">dt_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

        <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Decision Tree:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fiturdecisiontree.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 20
Best Fitur Decision Tree: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fiturdecisiontree.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memuat list fitur yang akan di-drop dari file pickle</span>
<span class="n">DecisionTree_drop</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;fiturdecisiontree.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menghilangkan &#39;is_safe&#39; dari setiap nama fitur</span>
<span class="n">DecisionTree_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">DecisionTree_drop</span><span class="p">]</span>

<span class="c1"># Memilih hanya kolom yang ada di pickle</span>
<span class="n">data_DecisionTree_drop</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">DecisionTree_drop</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]]</span>

<span class="c1"># Menampilkan DataFrame setelah fitur di-drop</span>
<span class="n">data_DecisionTree_drop</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
</section>
<section id="id2">
<h3>Ada Boost Classifier<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">best_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_feature_scores</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Menghitung nilai korelasi antara setiap fitur dengan target</span>
    <span class="n">k_best_selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Mendapatkan nama fitur terpilih</span>
    <span class="n">selected_feature_names</span> <span class="o">=</span> <span class="n">X_ros</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k_best_selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

    <span class="c1"># Membuat model Adaboost</span>
    <span class="n">adaboost_model</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Ganti dengan parameter yang sesuai</span>

    <span class="c1"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">adaboost_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_selected</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span>
    <span class="n">y_pred_adaboost</span> <span class="o">=</span> <span class="n">adaboost_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_selected</span><span class="p">)</span>

    <span class="c1"># Mengukur akurasi model Adaboost</span>
    <span class="n">accuracy_adaboost</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_adaboost</span><span class="p">)</span>

    <span class="c1"># Menyimpan skor korelasi untuk fitur terpilih</span>
    <span class="n">feature_scores</span> <span class="o">=</span> <span class="n">k_best_selector</span><span class="o">.</span><span class="n">scores_</span>

    <span class="c1"># Membandingkan dengan akurasi terbaik sejauh ini</span>
    <span class="k">if</span> <span class="n">accuracy_adaboost</span> <span class="o">&gt;</span> <span class="n">best_accuracy</span><span class="p">:</span>
        <span class="n">best_accuracy</span> <span class="o">=</span> <span class="n">accuracy_adaboost</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="n">best_selected_feature_names</span> <span class="o">=</span> <span class="n">selected_feature_names</span>
        <span class="n">best_feature_scores</span> <span class="o">=</span> <span class="n">feature_scores</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">adaboost_model</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">k_best_selector</span>

<span class="c1"># Menampilkan hasil terbaik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah Fitur :&quot;</span><span class="p">,</span> <span class="n">best_k</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Fitur Adaboost:&quot;</span><span class="p">,</span> <span class="n">best_selected_feature_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best Fitur Scores:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="n">best_feature_scores</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menyimpan nama fitur terpilih</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">best_selected_feature_names</span><span class="p">,</span> <span class="s1">&#39;fituradaboost.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah Fitur : 20
Best Fitur Adaboost: Index([&#39;aluminium&#39;, &#39;ammonia&#39;, &#39;arsenic&#39;, &#39;barium&#39;, &#39;cadmium&#39;, &#39;chloramine&#39;,
       &#39;chromium&#39;, &#39;copper&#39;, &#39;flouride&#39;, &#39;bacteria&#39;, &#39;viruses&#39;, &#39;lead&#39;,
       &#39;nitrates&#39;, &#39;nitrites&#39;, &#39;mercury&#39;, &#39;perchlorate&#39;, &#39;radium&#39;, &#39;selenium&#39;,
       &#39;silver&#39;, &#39;uranium&#39;],
      dtype=&#39;object&#39;)

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;fituradaboost.pkl&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Membaca DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data_balancing.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memuat list fitur yang akan di-drop dari file pickle</span>
<span class="n">Adaboost_drop</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;fituradaboost.pkl&#39;</span><span class="p">)</span>

<span class="c1"># Menghilangkan &#39;is_safe&#39; dari setiap nama fitur</span>
<span class="n">Adaboost_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">Adaboost_drop</span><span class="p">]</span>

<span class="c1"># Memilih hanya kolom yang ada di pickle</span>
<span class="n">data_Adaboost_drop</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Adaboost_drop</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]]</span>

<span class="c1"># Menampilkan DataFrame setelah fitur di-drop</span>
<span class="n">data_Adaboost_drop</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aluminium</th>
      <th>ammonia</th>
      <th>arsenic</th>
      <th>barium</th>
      <th>cadmium</th>
      <th>chloramine</th>
      <th>chromium</th>
      <th>copper</th>
      <th>flouride</th>
      <th>bacteria</th>
      <th>...</th>
      <th>lead</th>
      <th>nitrates</th>
      <th>nitrites</th>
      <th>mercury</th>
      <th>perchlorate</th>
      <th>radium</th>
      <th>selenium</th>
      <th>silver</th>
      <th>uranium</th>
      <th>is_safe</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.65</td>
      <td>9.08</td>
      <td>0.04</td>
      <td>2.85</td>
      <td>0.007</td>
      <td>0.35</td>
      <td>0.83</td>
      <td>0.17</td>
      <td>0.05</td>
      <td>0.20</td>
      <td>...</td>
      <td>0.054</td>
      <td>16.08</td>
      <td>1.13</td>
      <td>0.007</td>
      <td>37.75</td>
      <td>6.78</td>
      <td>0.08</td>
      <td>0.34</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.32</td>
      <td>21.16</td>
      <td>0.01</td>
      <td>3.31</td>
      <td>0.002</td>
      <td>5.28</td>
      <td>0.68</td>
      <td>0.66</td>
      <td>0.90</td>
      <td>0.65</td>
      <td>...</td>
      <td>0.100</td>
      <td>2.01</td>
      <td>1.93</td>
      <td>0.003</td>
      <td>32.26</td>
      <td>3.21</td>
      <td>0.08</td>
      <td>0.27</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.01</td>
      <td>14.02</td>
      <td>0.04</td>
      <td>0.58</td>
      <td>0.008</td>
      <td>4.24</td>
      <td>0.53</td>
      <td>0.02</td>
      <td>0.99</td>
      <td>0.05</td>
      <td>...</td>
      <td>0.078</td>
      <td>14.16</td>
      <td>1.11</td>
      <td>0.006</td>
      <td>50.28</td>
      <td>7.07</td>
      <td>0.07</td>
      <td>0.44</td>
      <td>0.01</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.36</td>
      <td>11.33</td>
      <td>0.04</td>
      <td>2.96</td>
      <td>0.001</td>
      <td>7.23</td>
      <td>0.03</td>
      <td>1.66</td>
      <td>1.08</td>
      <td>0.71</td>
      <td>...</td>
      <td>0.016</td>
      <td>1.41</td>
      <td>1.29</td>
      <td>0.004</td>
      <td>9.12</td>
      <td>1.72</td>
      <td>0.02</td>
      <td>0.45</td>
      <td>0.05</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.92</td>
      <td>24.33</td>
      <td>0.03</td>
      <td>0.20</td>
      <td>0.006</td>
      <td>2.67</td>
      <td>0.69</td>
      <td>0.57</td>
      <td>0.61</td>
      <td>0.13</td>
      <td>...</td>
      <td>0.117</td>
      <td>6.74</td>
      <td>1.11</td>
      <td>0.003</td>
      <td>16.90</td>
      <td>2.41</td>
      <td>0.02</td>
      <td>0.06</td>
      <td>0.02</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div></div></div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modeling">
<h1>Modeling<a class="headerlink" href="#modeling" title="Permalink to this heading">#</a></h1>
<section id="id3">
<h2>Light Gradient Boosting Machine<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p>Metode Light Gradient Boosting Machine (LightGBM) merupakan salah satu algoritma machine learning yang termasuk dalam kategori ensemble learning, khususnya dalam keluarga algoritma gradient boosting. LightGBM dikembangkan oleh Microsoft dan dirancang untuk memberikan kinerja yang cepat dan efisien, terutama pada dataset yang besar.</p>
<p>Berikut adalah beberapa karakteristik utama dari LightGBM:</p>
<ol class="arabic simple">
<li><p>Gradient Boosting Framework, jadi LightGBM merupakan implementasi dari algoritma gradient boosting, yang berfokus pada membangun model prediktif dengan cara menggabungkan beberapa model lemah (weak learners) menjadi satu model yang kuat.
Proses ini dilakukan secara iteratif, dengan setiap iterasi bertujuan untuk memperbaiki kesalahan prediksi yang dibuat oleh model sebelumnya.</p></li>
<li><p>Leaf-wise Growth Strategy, Salah satu fitur utama dari LightGBM adalah strategi pertumbuhan pohon secara daun (leaf-wise). Berbeda dengan pendekatan level-wise pada algoritma gradient boosting lainnya, LightGBM membangun pohon dengan mengekspansi daun yang memberikan kontribusi terbesar pada penurunan kesalahan (loss).
Strategi ini membantu meningkatkan efisiensi karena hanya daun yang signifikan yang diperluas.</p></li>
<li><p>Histogram-Based Learning, LightGBM menggunakan histogram untuk memproses data pada setiap iterasi pembelajaran. Histogram adalah representasi diskrit dari distribusi data, yang membantu mengurangi waktu komputasi.
Proses pembelajaran pada LightGBM membagi dataset ke dalam beberapa bucket histogram, dan kemudian menghitung statistik di setiap bucket untuk mempercepat pembelajaran.</p></li>
<li><p>Categorical Feature Support, LightGBM memiliki dukungan khusus untuk fitur kategorikal tanpa perlu melakukan pre-processing one-hot encoding. Ini membuatnya lebih efisien untuk menangani dataset dengan fitur kategorikal.</p></li>
<li><p>Distributed Training, LightGBM mendukung pelatihan terdistribusi, yang memungkinkan pengguna melatih model pada dataset yang sangat besar dengan menggunakan beberapa sumber daya komputasi secara bersamaan.</p></li>
<li><p>Regularization,LightGBM menyediakan opsi untuk menerapkan regularisasi pada pohon untuk mencegah overfitting. Regularisasi dapat diatur menggunakan parameter seperti lambda dan alpha.</p></li>
<li><p>Kecepatan dan Skalabilitas, Salah satu keunggulan utama LightGBM adalah kecepatan eksekusinya yang tinggi dan skalabilitasnya terhadap ukuran dataset. Hal ini membuatnya menjadi pilihan populer untuk tugas-tugas yang melibatkan data besar.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data_LightGradientBoostingMachine_drop</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_LightGradientBoostingMachine_drop</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train_lgbm</span><span class="p">,</span> <span class="n">X_test_lgbm</span><span class="p">,</span> <span class="n">y_train_lgbm</span><span class="p">,</span> <span class="n">y_test_lgbm</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_lightgbm</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_lgbm</span><span class="p">)</span>
<span class="n">X_test_lightgbm</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_lgbm</span><span class="p">)</span>

<span class="n">lightgbm_model</span> <span class="o">=</span> <span class="n">lightgbm</span>
<span class="n">lightgbm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_lightgbm</span><span class="p">,</span> <span class="n">y_train_lgbm</span><span class="p">)</span>
<span class="n">y_pred_lightgbm</span> <span class="o">=</span> <span class="n">lightgbm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_lightgbm</span><span class="p">)</span>
<span class="n">accuracy_lightgbm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_lgbm</span><span class="p">,</span> <span class="n">y_pred_lightgbm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Accuracy metode Light Gradient Boosting Machine :&quot;</span><span class="p">,</span><span class="n">accuracy_lightgbm</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RobustScaler</span><span class="p">,</span> <span class="s1">&#39;saclelightgbm.pkl&#39;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lightgbm_model</span><span class="p">,</span> <span class="s1">&#39;modellightgbm.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003947 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3018
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059

Accuracy metode Light Gradient Boosting Machine : 98.37708830548925
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modellightgbm.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h2>Gradient Boosting Classifier<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>Metode Gradient Boosting adalah salah satu pendekatan dalam machine learning yang termasuk dalam kategori ensemble learning. Ensemble learning melibatkan penggabungan beberapa model lemah (weak learners) untuk membentuk model yang lebih kuat. Gradient Boosting secara khusus fokus pada pengurangan kesalahan prediksi dengan memperhatikan kesalahan model sebelumnya.</p>
<p>Berikut adalah konsep dasar dari metode Gradient Boosting:</p>
<ol class="arabic simple">
<li><p>Weak learners adalah model prediktif yang memiliki performa yang sedikit di atas random chance. Contohnya termasuk decision trees dengan kedalaman yang sangat terbatas (stump) atau regresi linear sederhana.
Dalam konteks Gradient Boosting, sejumlah besar weak learners akan digabungkan untuk membentuk model yang kuat.
Sequential Model Building:</p></li>
<li><p>Proses Gradient Boosting melibatkan pembangunan model secara iteratif. Pada setiap iterasi, model baru ditambahkan untuk mengkompensasi kesalahan prediksi yang belum ditangani oleh model sebelumnya. Model yang baru ditambahkan harus “mengajar” untuk kesalahan yang ada. Ini dilakukan dengan meminimalkan residual error (selisih antara prediksi aktual dan prediksi model sebelumnya) menggunakan weak learner.</p></li>
<li><p>Loss function (fungsi kerugian) digunakan untuk mengukur sejauh mana model saat ini memberikan prediksi yang benar atau mendekati target aktual. Pada setiap iterasi, model berusaha meminimalkan nilai loss function. Contoh loss function untuk regresi adalah Mean Squared Error (MSE), sementara untuk klasifikasi bisa menggunakan log-likelihood atau Gini Index.</p></li>
<li><p>Gradient descent digunakan untuk menemukan parameter model yang meminimalkan loss function. Pada setiap iterasi, model baru ditambahkan dengan menyesuaikan parameter (misalnya, bobot pohon pada decision tree) dalam arah yang berlawanan dengan gradien loss function. Proses ini memungkinkan model untuk fokus pada bagian dataset yang sulit diprediksi oleh model sebelumnya.</p></li>
<li><p>Shrinkage adalah parameter yang mengontrol seberapa besar kita akan “mempelajari” dari setiap model tambahan. Nilai shrinkage yang lebih rendah memerlukan lebih banyak iterasi untuk mencapai kinerja yang baik, tetapi dapat meningkatkan kestabilan model.</p></li>
<li><p>Beberapa implementasi Gradient Boosting, seperti XGBoost atau LightGBM, memiliki opsi untuk menerapkan teknik regularisasi untuk mencegah overfitting. Regularisasi dapat diatur dengan menggunakan parameter tertentu, seperti lambda dan alpha.</p></li>
<li><p>Gradient Boosting mirip dengan metode AdaBoost, tetapi ada perbedaan kunci. Jika AdaBoost memberikan “perhatian lebih” pada contoh yang salah diprediksi sebelumnya, Gradient Boosting fokus pada residual errors atau gradien loss function.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data_GradientBoostingClasifier_drop</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_GradientBoostingClasifier_drop</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train_gbc</span><span class="p">,</span> <span class="n">X_test_gbc</span><span class="p">,</span> <span class="n">y_train_gbc</span><span class="p">,</span> <span class="n">y_test_gbc</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_GradientBoosting</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_gbc</span><span class="p">)</span>
<span class="n">X_test_GradientBoosting</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_gbc</span><span class="p">)</span>

<span class="n">gbc_model</span> <span class="o">=</span> <span class="n">gbc</span>
<span class="n">gbc_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_GradientBoosting</span><span class="p">,</span> <span class="n">y_train_gbc</span><span class="p">)</span>
<span class="n">y_pred_gbc</span> <span class="o">=</span> <span class="n">gbc_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_GradientBoosting</span><span class="p">)</span>
<span class="n">accuracy_gbc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_gbc</span><span class="p">,</span> <span class="n">y_pred_gbc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy metode Gradient Boosting Clasifier :&quot;</span><span class="p">,</span><span class="n">accuracy_gbc</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RobustScaler</span><span class="p">,</span> <span class="s1">&#39;saclergbc.pkl&#39;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">gbc_model</span><span class="p">,</span> <span class="s1">&#39;modelgbc.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy metode Gradient Boosting Clasifier : 95.13126491646779
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modelgbc.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h2>Random Forest<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<p>Random Forest adalah sebuah metode ensemble learning yang digunakan dalam pemodelan prediktif dan klasifikasi. Ensemble learning melibatkan penggabungan hasil dari beberapa model untuk meningkatkan kinerja dan akurasi keseluruhan. Random Forest khususnya menggunakan pohon keputusan sebagai model dasar dan menggabungkan prediksi dari beberapa pohon keputusan untuk membuat keputusan akhir.</p>
<p>Random Forest efektif untuk berbagai jenis tugas seperti klasifikasi dan regresi, dan sering digunakan karena kemampuannya yang baik dalam menangani data yang kompleks dan beragam. Keunggulan utamanya termasuk kemampuan untuk mengatasi overfitting, memberikan nilai penting untuk fitur, dan memberikan performa yang baik secara umum.</p>
<p>Berikut adalah contoh sederhana bagaimana kita bisa menghitung prediksi menggunakan Random Forest dengan tiga pohon:</p>
<p>Misalkan kita memiliki tiga pohon keputusan yang masing-masing memberikan prediksi sebagai berikut untuk suatu titik data:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Pohon</p></th>
<th class="head"><p>Prediksi</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>A</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>B</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>A</p></td>
</tr>
</tbody>
</table>
<p>Dalam hal ini, Random Forest akan memberikan prediksi akhir “Kelas A” karena ini adalah kelas yang paling sering diprediksi oleh pohon-pohon dalam hutan.</p>
<ul class="simple">
<li><p><b>Contoh Penerapan</b></p></li>
</ul>
<p>Misalkan kita memiliki data kategori obesitas dengan fitur seperti Usia, Tinggi (TB), dan Berat Badan (BB), dan target kita adalah kategori obesitas. Kita bisa menggunakan Random Forest untuk memprediksi jumlah unit yang akan diproduksi berdasarkan fitur-fitur tersebut.</p>
<p><b>1. Persiapan Data</b></p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Usia</p></th>
<th class="head"><p>Tinggi Badan</p></th>
<th class="head"><p>Berat Badan</p></th>
<th class="head"><p>Target Kategori</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>25</p></td>
<td><p>170</p></td>
<td><p>70</p></td>
<td><p>Normal</p></td>
</tr>
<tr class="row-odd"><td><p>30</p></td>
<td><p>170</p></td>
<td><p>60</p></td>
<td><p>Normal</p></td>
</tr>
<tr class="row-even"><td><p>35</p></td>
<td><p>180</p></td>
<td><p>80</p></td>
<td><p>Obesitas</p></td>
</tr>
</tbody>
</table>
<p><b>2. Pelatihan Model</b></p>
<p>Kedua, kita melatih model Random Forest menggunakan data historis tersebut. Model akan mempelajari hubungan kompleks antara “Usia”, “Tinggi Badan”, “Berat Badan”, dan target “Kategori Obesitas”.</p>
<p><b>3. Penggunaan Model Untuk Prediksi</b></p>
<p>Setelah melatih model, kita dapat menggunakannya untuk memprediksi kategori obesitas berdasarkan fitur-fitur baru. Misalkan kita memiliki data baru seperti berikut:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Usia</p></th>
<th class="head"><p>Tinggi Badan</p></th>
<th class="head"><p>Berat Badan</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>28</p></td>
<td><p>175</p></td>
<td><p>75</p></td>
</tr>
</tbody>
</table>
<p><b>4. Hasil Prediksi</b>
Model kita kemudian memberikan prediksi kategori obesitas berikut:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Usia</p></th>
<th class="head"><p>Tinggi Badan</p></th>
<th class="head"><p>Berat Badan</p></th>
<th class="head"><p>Target Kategori</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>28</p></td>
<td><p>175</p></td>
<td><p>75</p></td>
<td><p>Obesitas</p></td>
</tr>
</tbody>
</table>
<p>Dalam contoh ini, model Random Forest memprediksi bahwa dengan usia 28 tahun, tinggi badan 175 cm, dan berat badan 75 kg, seseorang termasuk dalam kategori “Obesitas”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data_RandomForest_drop</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_RandomForest_drop</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train_rf</span><span class="p">,</span> <span class="n">X_test_rf</span><span class="p">,</span> <span class="n">y_train_rf</span><span class="p">,</span> <span class="n">y_test_rf</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_RandomForest</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_rf</span><span class="p">)</span>
<span class="n">X_test_RandomForest</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_rf</span><span class="p">)</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">rf</span>
<span class="n">rf_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_RandomForest</span><span class="p">,</span> <span class="n">y_train_rf</span><span class="p">)</span>
<span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_RandomForest</span><span class="p">)</span>
<span class="n">accuracy_rf</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_rf</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy metode Random Forest :&quot;</span><span class="p">,</span><span class="n">accuracy_rf</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RobustScaler</span><span class="p">,</span> <span class="s1">&#39;saclerrandomforest.pkl&#39;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf_model</span><span class="p">,</span> <span class="s1">&#39;modelrandomforest.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy metode Random Forest : 98.71121718377088
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modelrandomforest.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h2>Decision Tree Clasifier<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h2>
<p>Decision Tree, atau pohon keputusan, adalah salah satu algoritma pembelajaran mesin yang dapat digunakan untuk tugas klasifikasi dan regresi. Algoritma ini membangun struktur pohon di mana setiap simpul (node) mewakili keputusan berdasarkan fitur-fitur data. Pada setiap simpul, algoritma membuat keputusan berdasarkan fitur tertentu, sehingga memungkinkan pemisahan data menjadi kelompok yang semakin homogen.</p>
<p>Keunggulan Decision Tree:</p>
<ol class="arabic simple">
<li><p>Interpretabilitas: Pohon keputusan dapat dengan mudah diinterpretasikan oleh manusia karena strukturnya mirip dengan keputusan yang diambil berdasarkan aturan sederhana.</p></li>
<li><p>Penanganan Fitur Non-Lineer: Decision Tree dapat menangani hubungan non-linear antara fitur dan target.</p></li>
<li><p>Skalabilitas: Cocok untuk dataset dengan banyak fitur dan data yang cukup besar.</p></li>
</ol>
<ul class="simple">
<li><p>Contoh Penerapan:</p></li>
</ul>
<ol class="arabic simple">
<li><p>Persiapan Data
Misalkan kita memiliki data mengenai konsumen yang ingin kita kelompokkan berdasarkan keputusan pembelian suatu produk. Data tersebut mungkin terlihat seperti ini:</p></li>
</ol>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Umur</p></th>
<th class="head"><p>Pendapatan</p></th>
<th class="head"><p>Pendidikan</p></th>
<th class="head"><p>Keputusan Pembelian</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>25</p></td>
<td><p>50000</p></td>
<td><p>Sarjana</p></td>
<td><p>Ya</p></td>
</tr>
<tr class="row-odd"><td><p>35</p></td>
<td><p>75000</p></td>
<td><p>Master</p></td>
<td><p>Tidak</p></td>
</tr>
<tr class="row-even"><td><p>45</p></td>
<td><p>100000</p></td>
<td><p>Doktor</p></td>
<td><p>Ya</p></td>
</tr>
</tbody>
</table>
<ol class="arabic simple" start="2">
<li><p>Pelatihan Model
Selanjutnya, kita melatih model Decision Tree menggunakan data historis tersebut. Model akan mempelajari aturan-aturan keputusan berdasarkan fitur-fitur seperti “Umur”, “Pendapatan”, dan “Pendidikan”.</p></li>
<li><p>Penggunaan Model Untuk Prediksi
Setelah pelatihan, kita dapat menggunakan model untuk memprediksi keputusan pembelian konsumen baru. Misalkan kita memiliki data baru:</p></li>
</ol>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Umur</p></th>
<th class="head"><p>Pendapatan</p></th>
<th class="head"><p>Pendidikan</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>30</p></td>
<td><p>60000</p></td>
<td><p>Diploma</p></td>
</tr>
</tbody>
</table>
<ol class="arabic simple" start="4">
<li><p>Hasil Prediksi</p></li>
</ol>
<p>Model Decision Tree kemudian memberikan prediksi keputusan pembelian, misalnya, “Ya” atau “Tidak”, berdasarkan aturan yang telah dipelajari dari data historis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data_DecisionTree_drop</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_DecisionTree_drop</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train_dt</span><span class="p">,</span> <span class="n">X_test_dt</span><span class="p">,</span> <span class="n">y_train_dt</span><span class="p">,</span> <span class="n">y_test_dt</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_DecisionTree</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_dt</span><span class="p">)</span>
<span class="n">X_test_DecisionTree</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_dt</span><span class="p">)</span>

<span class="n">dt_model</span> <span class="o">=</span> <span class="n">dt</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_DecisionTree</span><span class="p">,</span> <span class="n">y_train_dt</span><span class="p">)</span>
<span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_DecisionTree</span><span class="p">)</span>
<span class="n">accuracy_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy metode Decision Tree :&quot;</span><span class="p">,</span><span class="n">accuracy_dt</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RobustScaler</span><span class="p">,</span> <span class="s1">&#39;saclerdecisiontree.pkl&#39;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span> <span class="s1">&#39;modeldecisiontree.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy metode Decision Tree : 98.18615751789976
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modeldecisiontree.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h2>Ada Boost Classifier<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h2>
<p>Adaboost menggabungkan hasil dari sejumlah besar weak classifiers (misalnya, pohon keputusan yang sangat sederhana) untuk membentuk model yang kuat. Setiap weak classifier diberi bobot berdasarkan seberapa baik mereka menangani sampel pada iterasi sebelumnya. Proses ini dilakukan secara iteratif, dan pada setiap iterasi, bobot baru diberikan pada sampel yang salah diprediksi pada iterasi sebelumnya.</p>
<p>Dengan kata lain, jika kita memiliki M weak classifiers, prediksi model ensemble Adaboost (( F(x) )) dapat dihitung dengan:</p>
<div class="math notranslate nohighlight">
\[  F(x) = \sum_{m=1}^{M} \alpha_m \cdot f_m(x)  \]</div>
<p>di mana:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( F(x) \)</span> adalah prediksi model ensemble.</p></li>
<li><p><span class="math notranslate nohighlight">\( \alpha_m \)</span> adalah bobot yang diberikan pada weak classifier ke-m.</p></li>
<li><p><span class="math notranslate nohighlight">\( f_m(x) \)</span> adalah prediksi dari weak classifier ke-m.</p></li>
</ul>
<p>Bobot <span class="math notranslate nohighlight">\( \alpha_m \)</span> dihitung berdasarkan tingkat kesalahan weak classifier pada iterasi sebelumnya. Semakin baik weak classifier menangani sampel, semakin besar bobotnya.</p>
<p>Bentuk umum ini mencerminkan kombinasi linear dari weak classifiers, dan dengan strategi ini, Adaboost dapat memperbaiki performa model terhadap sampel yang sulit diprediksi oleh model sebelumnya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data_Adaboost_drop</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;is_safe&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_Adaboost_drop</span><span class="p">[</span><span class="s1">&#39;is_safe&#39;</span><span class="p">]</span>
<span class="n">X_train_ada</span><span class="p">,</span> <span class="n">X_test_ada</span><span class="p">,</span> <span class="n">y_train_ada</span><span class="p">,</span> <span class="n">y_test_ada</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">RobustScaler</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">()</span>
<span class="n">X_train_adaboost</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_ada</span><span class="p">)</span>
<span class="n">X_test_adaboost</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test_ada</span><span class="p">)</span>

<span class="n">ada_model</span> <span class="o">=</span> <span class="n">ada</span>
<span class="n">ada_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_adaboost</span><span class="p">,</span> <span class="n">y_train_ada</span><span class="p">)</span>
<span class="n">y_pred_ada</span> <span class="o">=</span> <span class="n">ada_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_adaboost</span><span class="p">)</span>
<span class="n">accuracy_ada</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_ada</span><span class="p">,</span> <span class="n">y_pred_ada</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy metode Adaboost :&quot;</span><span class="p">,</span><span class="n">accuracy_ada</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RobustScaler</span><span class="p">,</span> <span class="s1">&#39;sacleradaboost.pkl&#39;</span><span class="p">)</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">ada_model</span><span class="p">,</span> <span class="s1">&#39;modeladaboost.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy metode Adaboost : 87.9236276849642
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modeladaboost.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="perbandingan-metode">
<h2>Perbandingan Metode<a class="headerlink" href="#perbandingan-metode" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Light Gradient Boosting Machine&#39;</span><span class="p">,</span> <span class="s1">&#39;Gradient Boosting&#39;</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span> <span class="s1">&#39;Adaboost&#39;</span><span class="p">]</span>

<span class="c1"># Daftar akurasi dari setiap metode</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">accuracy_lightgbm</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_gbc</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_rf</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_dt</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="n">accuracy_ada</span><span class="o">*</span><span class="mi">100</span><span class="p">]</span>

<span class="c1"># Membuat dataframe dari data</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Metode&#39;</span><span class="p">:</span> <span class="n">methods</span><span class="p">,</span> <span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">:</span> <span class="n">accuracies</span><span class="p">}</span>
<span class="n">dataa</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Membuat grafik bar dengan Seaborn</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Metode&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataa</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;pastel&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Metode&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Akurasi (%)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi antara Metode&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1"># Menambahkan nilai-nilai akurasi di atas setiap batang</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">accuracies</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="o">-</span> <span class="mi">50</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/051b7e6c4a9738f3621c6d7d6bfadfe398a23959d7e396cc10cb657da6b18552.png" src="_images/051b7e6c4a9738f3621c6d7d6bfadfe398a23959d7e396cc10cb657da6b18552.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluasi">
<h1>Evaluasi<a class="headerlink" href="#evaluasi" title="Permalink to this heading">#</a></h1>
<p>Evaluasi dalam konteks model prediktif dan klasifikasi merujuk pada penilaian kinerja model terhadap data yang belum pernah dilihat sebelumnya atau data uji. Tujuan evaluasi adalah untuk memahami sejauh mana model dapat menggeneralis ke data baru dan seberapa baik model dapat melakukan tugasnya, seperti klasifikasi dengan akurasi tinggi atau regresi dengan presisi yang baik. Berikut adalah beberapa metrik evaluasi umum:</p>
<ol class="arabic simple">
<li><p>Akurasi (Accuracy) mengukur sejauh mana model dapat mengklasifikasikan data dengan benar. Akurasi dinyatakan sebagai persentase dari total prediksi yang benar.
$<span class="math notranslate nohighlight">\(\text{Accuracy} = \frac{\text{True Positive} + \text{True Negative}}{\text{Total Data}}\)</span>$</p></li>
<li><p>Recall (Sensitivitas atau True Positive Rate) mengukur sejauh mana model dapat mengidentifikasi semua instance yang benar positif dari kelas tertentu. Recall berguna ketika menghindari false negatives sangat penting.
$<span class="math notranslate nohighlight">\(\text{Recall} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}}\)</span>$</p></li>
<li><p>Precision mengukur sejauh mana prediksi positif model yang benar-benar benar. Precision berguna ketika menghindari false positives sangat penting.
$<span class="math notranslate nohighlight">\(\text{Precision} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive}}\)</span>$</p></li>
<li><p>F1 Score adalah harmonic mean dari precision dan recall. Ini memberikan keseimbangan antara precision dan recall. F1 Score tinggi menunjukkan keseimbangan yang baik antara precision dan recall.
$<span class="math notranslate nohighlight">\(\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\)</span>$</p></li>
<li><p>Classification Report:</p>
<ul class="simple">
<li><p>Menyajikan statistik klasifikasi seperti precision, recall, dan f1-score untuk setiap kelas.</p></li>
<li><p>Dalam classification report, Anda akan mendapatkan informasi ini untuk setiap kelas.</p></li>
</ul>
</li>
</ol>
<section id="id8">
<h2>Light Gradient Boosting Machine<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_lgbm</span><span class="p">,</span> <span class="n">y_pred_lightgbm</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_lgbm</span><span class="p">,</span> <span class="n">y_pred_lightgbm</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_test_lgbm</span><span class="p">,</span> <span class="n">y_pred_lightgbm</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      0.97      0.98      1039
           1       0.97      1.00      0.98      1056

    accuracy                           0.98      2095
   macro avg       0.98      0.98      0.98      2095
weighted avg       0.98      0.98      0.98      2095
</pre></div>
</div>
<img alt="_images/f11c7a44c4b266fd6ca4704e2c7829570c838aacbc0634516d8c6525f4ab55c0.png" src="_images/f11c7a44c4b266fd6ca4704e2c7829570c838aacbc0634516d8c6525f4ab55c0.png" />
</div>
</div>
</section>
<section id="id9">
<h2>Gradient Boosting Classifier<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_gbc</span><span class="p">,</span> <span class="n">y_pred_gbc</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_gbc</span><span class="p">,</span> <span class="n">y_pred_gbc</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_test_gbc</span><span class="p">,</span> <span class="n">y_pred_gbc</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.97      0.93      0.95      1039
           1       0.93      0.97      0.95      1056

    accuracy                           0.95      2095
   macro avg       0.95      0.95      0.95      2095
weighted avg       0.95      0.95      0.95      2095
</pre></div>
</div>
<img alt="_images/d8f4808cc45010e7ac7cbf75ad0e99c7b9f29b040ab6869ac6e025e7d425550b.png" src="_images/d8f4808cc45010e7ac7cbf75ad0e99c7b9f29b040ab6869ac6e025e7d425550b.png" />
</div>
</div>
</section>
<section id="id10">
<h2>Random Forest<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_rf</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_rf</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_test_rf</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      0.97      0.99      1039
           1       0.98      1.00      0.99      1056

    accuracy                           0.99      2095
   macro avg       0.99      0.99      0.99      2095
weighted avg       0.99      0.99      0.99      2095
</pre></div>
</div>
<img alt="_images/e45320a0329a5f2a2c34179f247f703502a46fc63e7e6d77d61b078759188b7f.png" src="_images/e45320a0329a5f2a2c34179f247f703502a46fc63e7e6d77d61b078759188b7f.png" />
</div>
</div>
</section>
<section id="id11">
<h2>Decision Tree Clasifier<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_test_dt</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      0.97      0.98      1039
           1       0.97      1.00      0.98      1056

    accuracy                           0.98      2095
   macro avg       0.98      0.98      0.98      2095
weighted avg       0.98      0.98      0.98      2095
</pre></div>
</div>
<img alt="_images/fc2eee774ddfbe38aecd1d608d8b41060962d476abdc7bf1613f673ba0305ba8.png" src="_images/fc2eee774ddfbe38aecd1d608d8b41060962d476abdc7bf1613f673ba0305ba8.png" />
</div>
</div>
</section>
<section id="id12">
<h2>Ada Boost Classifier<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_ada</span><span class="p">,</span> <span class="n">y_pred_ada</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_ada</span><span class="p">,</span> <span class="n">y_pred_ada</span><span class="p">)</span>
<span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_test_ada</span><span class="p">,</span> <span class="n">y_pred_ada</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">class_labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Actual&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.87      0.89      0.88      1039
           1       0.89      0.87      0.88      1056

    accuracy                           0.88      2095
   macro avg       0.88      0.88      0.88      2095
weighted avg       0.88      0.88      0.88      2095
</pre></div>
</div>
<img alt="_images/79fd57ebf1e0471228d006c9cb4533cfb506b4ca9900061a81f747605e02d591.png" src="_images/79fd57ebf1e0471228d006c9cb4533cfb506b4ca9900061a81f747605e02d591.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="deployment">
<h1>Deployment<a class="headerlink" href="#deployment" title="Permalink to this heading">#</a></h1>
<p>Silahkan klik <a class="reference external" href="https://210411100140-mubessirulummah-psd-mubessir-1-randomforest-yibzz4.streamlit.app/">https://210411100140-mubessirulummah-psd-mubessir-1-randomforest-yibzz4.streamlit.app/</a> untuk melihat deploynya.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Welcome to your Jupyter Book</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">BUSINESS UNDERSTANDING</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determine-business-objectives-menentukan-tujuan-bisnis">Determine Business Objectives (Menentukan Tujuan Bisnis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#access-situation-menilai-situasi">Access Situation (Menilai Situasi)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#determine-data-mining-goals-menentukan-tujuan-data-mining">Determine Data Mining Goals (Menentukan Tujuan Data Mining)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#produce-project-plan-menghasilkan-rencana-proyek">Produce Project Plan (Menghasilkan Rencana Proyek)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding">DATA UNDERSTANDING</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-dataset">Deskripsi Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-fitur-dataset">Deskripsi Fitur Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-tipe-data-fitur">Deskripsi Tipe Data Fitur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-missing-value">Identifikasi Missing Value</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-data-duplicated">Identifikasi Data Duplicated</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-sebaran-kelas-data">Identifikasi Sebaran Kelas Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-outlier">Identifikasi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#eksplorasi-data">Eksplorasi Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#histogram-sebaran-frekuensi-data-setiap-kolom">Histogram Sebaran Frekuensi Data Setiap Kolom</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-korelasi">Matrix Korelasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diagram-lingkaran-perbandingan-jumlah-data-kelas">Diagram Lingkaran perbandingan jumlah data kelas</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-procesing">Pre-Procesing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-missing-data">Handling Missing Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-cleaning">Data Cleaning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-imbalanced-data">Handling Imbalanced Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-kelas-data-awal">Perbandingan kelas data awal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proses-balancing-data">Proses Balancing Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">Feature Scaling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#splitting-data">Splitting Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pycaret-seleksi-model">Pycaret Seleksi Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#light-gradient-boosting-machine">Light Gradient Boosting Machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-classifier">Gradient Boosting Classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-clasifier">Decision Tree Clasifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ada-boost-classifier">Ada Boost Classifier</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection">Feature Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-light-gradient-boosting-machine">Pencarian Fitur Terbaik Light Gradient Boosting Machine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-gradient-boosting-classifier">Pencarian Fitur Terbaik Gradient Boosting Classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pencarian-fitur-terbaik-random-forest">Pencarian Fitur Terbaik Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Decision Tree Clasifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Ada Boost Classifier</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Light Gradient Boosting Machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Gradient Boosting Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Random Forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Decision Tree Clasifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Ada Boost Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-metode">Perbandingan Metode</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi">Evaluasi</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Light Gradient Boosting Machine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">Gradient Boosting Classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">Random Forest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">Decision Tree Clasifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">Ada Boost Classifier</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment">Deployment</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>